{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0fNpxAUWVpyx"
      },
      "id": "0fNpxAUWVpyx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Motamensalih/RAG_First_Project/blob/main/examples/1-managing-data/embeddings.ipynb"
      ],
      "metadata": {
        "id": "AlQH-HSIVpDx"
      },
      "id": "AlQH-HSIVpDx"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d566bb99-6808-4976-8476-ed05b7941b80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d566bb99-6808-4976-8476-ed05b7941b80",
        "outputId": "11cf02fe-cb59-4096-f929-f46259b422e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/RAG_First_Project/top_rated_wines.csv')\n",
        "df = df[df['variety'].notna()] # remove any NaN values as it blows up serialization\n",
        "data = df.sample(700).to_dict('records') # Get only 700 records. More records will make it slower to index\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "af8bce2c-e123-498a-a5f2-cefffd17fc74",
      "metadata": {
        "id": "af8bce2c-e123-498a-a5f2-cefffd17fc74"
      },
      "outputs": [],
      "source": [
        "#!pip install huggingface-hub==0.25.2 # Install huggingface-hub version 0.25.2 which has the function.\n",
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "source": [
        "!pip install huggingface-hub==0.25.2 # Install huggingface-hub version 0.25.2 which has the function."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XcRSCucPJNe5"
      },
      "id": "XcRSCucPJNe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2b0e4be5-7518-4458-bf47-6913ef9a72a9",
      "metadata": {
        "id": "2b0e4be5-7518-4458-bf47-6913ef9a72a9"
      },
      "outputs": [],
      "source": [
        "encoder = SentenceTransformer('all-MiniLM-L6-v2') # Model to create embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5efa031d-b18a-4db1-9c34-9989a15c822b",
      "metadata": {
        "id": "5efa031d-b18a-4db1-9c34-9989a15c822b"
      },
      "outputs": [],
      "source": [
        "# create the vector database client\n",
        "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6c03be93-a076-425e-8df1-5a8b6367e558",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c03be93-a076-425e-8df1-5a8b6367e558",
        "outputId": "fa80269b-f1d0-44b2-c84b-dbd4c7f4ea3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-36d8e74a557e>:2: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant.recreate_collection(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Create collection to store wines\n",
        "qdrant.recreate_collection(\n",
        "    collection_name=\"top_wines\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "655d08af-758f-4338-b112-cf94045c7b0d",
      "metadata": {
        "id": "655d08af-758f-4338-b112-cf94045c7b0d"
      },
      "outputs": [],
      "source": [
        "# vectorize!\n",
        "qdrant.upload_points(\n",
        "    collection_name=\"top_wines\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"notes\"]).tolist(),\n",
        "            payload=doc,\n",
        "        ) for idx, doc in enumerate(data) # data is the variable holding all the wines\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f23bc999",
      "metadata": {
        "id": "f23bc999"
      },
      "outputs": [],
      "source": [
        "user_prompt = \"Suggest me an amazing Malbec wine from Argentina\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "68c9bff5-db38-4a98-b542-cd173af11b53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68c9bff5-db38-4a98-b542-cd173af11b53",
        "outputId": "d76cb954-58d7-4dd4-a97b-fa9e509d423c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Bruno Rocca Barbaresco Rabaja 2000', 'region': 'Barbaresco, Piedmont, Italy', 'variety': 'Red Wine', 'rating': 97.0, 'notes': 'Unbelievable aromas, with rich, ripe plum but also mineral, tobacco and cedar undertones. Full-bodied, with lovely ripe tannins and a unctuous combination of ripe fruit and light toasty oak. Goes on and on. Fabulous. Greatest wine ever from Bruno Rocca. Best after 2007. 1,500 cases made. (JS)'} score: 0.6026552019512349\n",
            "{'name': 'Jorge Ordonez Number 4 Esencia (375ML half-bottle) 2004', 'region': 'Spain', 'variety': 'Boutique', 'rating': 99.0, 'notes': 'Esencia is a unique wine that incorporates the raisined muscat grape.  After 24 months in barrel, we achieve a partial fermentation of the must.  Alois Kracher, through this wine, sought to convey the essence of the village of Almáchar, in the heart of the Axarquía, famous from time immemorial for its delicious muscat grapes and raisins.  '} score: 0.5889358363836907\n",
            "{'name': \"Brovia Ca'Mia Barolo (1.5 Liter Magnum) 2006\", 'region': 'Barolo, Piedmont, Italy', 'variety': 'Red Wine', 'rating': 96.0, 'notes': \"A very complete and long aging wine from a great vineyard of Serralunga d'Alba. The color is intense ruby red. The smell is intense, pleasant, balanced and spicy with a bouquet of plums, cedar, tobacco, liquorice, soy and floral notes. The taste is full bodied, concentrated and rich, with a firm tannic structure that classic Barolo needs for a long aging.\"} score: 0.5783141316384215\n"
          ]
        }
      ],
      "source": [
        "# Search time for awesome wines!\n",
        "\n",
        "hits = qdrant.search(\n",
        "    collection_name=\"top_wines\",\n",
        "    query_vector=encoder.encode(user_prompt).tolist(),\n",
        "    limit=3\n",
        ")\n",
        "for hit in hits:\n",
        "  print(hit.payload, \"score:\", hit.score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "33243e5d-9e0d-4ec4-98e9-3fc56b8bdb10",
      "metadata": {
        "id": "33243e5d-9e0d-4ec4-98e9-3fc56b8bdb10"
      },
      "outputs": [],
      "source": [
        "# define a variable to hold the search results\n",
        "search_results = [hit.payload for hit in hits]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.11.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxiKCTBjKO5R",
        "outputId": "0a0425da-a1d0-44cf-d0a2-59a4f77c5038"
      },
      "id": "hxiKCTBjKO5R",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.11.1\n",
            "  Using cached openai-1.11.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.11/dist-packages (from openai==1.11.1) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.11.1) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.11.1) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.11.1) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.11.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.11.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.11.1) (2.27.2)\n",
            "Using cached openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.27.8\n",
            "    Uninstalling openai-0.27.8:\n",
            "      Successfully uninstalled openai-0.27.8\n",
            "Successfully installed openai-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e6c2b91e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "e6c2b91e",
        "outputId": "66d8d6db-c348-487c-d414-f8b5352a93f0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-059e92d7428a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now time to connect to the local large language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m client = OpenAI(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"http://127.0.0.1:8080/v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# \"http://<Your api-server IP>:port\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sk-no-key-required\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://api.openai.com/v1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0m_strict_response_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_strict_response_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         )\n\u001b[0;32m--> 793\u001b[0;31m         self._client = http_client or SyncHttpxClientWrapper(\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0;31m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ],
      "source": [
        "# Now time to connect to the local large language model\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    base_url=\"http://127.0.0.1:8080/v1\", # \"http://<Your api-server IP>:port\"\n",
        "    api_key = \"sk-no-key-required\"\n",
        ")\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"LLaMA_CPP\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are chatbot, a wine specialist. Your top priority is to help guide users into selecting amazing wine and guide them with their requests.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Suggest me an amazing Malbec wine from Argentina\"},\n",
        "        {\"role\": \"assistant\", \"content\": str(search_results)}\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Motamensalih/RAG_First_Project.git"
      ],
      "metadata": {
        "id": "QWyIPoffFEgU"
      },
      "id": "QWyIPoffFEgU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RAG_First_Project\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "sMEj620BFKwM"
      },
      "id": "sMEj620BFKwM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1eP6tm8fFScS"
      },
      "id": "1eP6tm8fFScS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USczWrm1K75g"
      },
      "id": "USczWrm1K75g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWbvQaBfK72Q"
      },
      "id": "wWbvQaBfK72Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPn8Zz-OK7zg"
      },
      "id": "vPn8Zz-OK7zg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/RAG_First_Project/top_rated_wines.csv')\n",
        "df = df[df['variety'].notna()] # remove any NaN values as it blows up serialization\n",
        "data = df.to_dict('records')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "Dp6A6Ed-K7wI",
        "outputId": "096de0aa-054f-488e-c38a-1e226c2793a6"
      },
      "id": "Dp6A6Ed-K7wI",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   name  \\\n",
              "0                           3 Rings Reserve Shiraz 2004   \n",
              "1                         Abreu Vineyards Cappella 2007   \n",
              "2                         Abreu Vineyards Cappella 2010   \n",
              "3                  Abreu Vineyards Howell Mountain 2008   \n",
              "4                  Abreu Vineyards Howell Mountain 2009   \n",
              "...                                                 ...   \n",
              "1360                Lewis Cellars Alec's Blend Red 2002   \n",
              "1361              Lewis Cellars Cabernet Sauvignon 2002   \n",
              "1362      Lewis Cellars Cuvee L Cabernet Sauvignon 2015   \n",
              "1363      Lewis Cellars Reserve Cabernet Sauvignon 2010   \n",
              "1364  Lewis Cellars Reserve Cabernet Sauvignon (scuf...   \n",
              "\n",
              "                                                 region   variety  rating  \\\n",
              "0     Barossa Valley, Barossa, South Australia, Aust...  Red Wine    96.0   \n",
              "1                               Napa Valley, California  Red Wine    96.0   \n",
              "2                               Napa Valley, California  Red Wine    98.0   \n",
              "3              Howell Mountain, Napa Valley, California  Red Wine    96.0   \n",
              "4              Howell Mountain, Napa Valley, California  Red Wine    98.0   \n",
              "...                                                 ...       ...     ...   \n",
              "1360                            Napa Valley, California  Red Wine    96.0   \n",
              "1361                            Napa Valley, California  Red Wine    96.0   \n",
              "1362                            Napa Valley, California  Red Wine    96.0   \n",
              "1363                            Napa Valley, California  Red Wine    96.0   \n",
              "1364                            Napa Valley, California  Red Wine    96.0   \n",
              "\n",
              "                                                  notes  \n",
              "0     Vintage Comments : Classic Barossa vintage con...  \n",
              "1     Cappella is a proprietary blend of two clones ...  \n",
              "2     Cappella is one of the oldest vineyard sites i...  \n",
              "3     When David purchased this Howell Mountain prop...  \n",
              "4     As a set of wines, it is hard to surpass the f...  \n",
              "...                                                 ...  \n",
              "1360                                      Number 12 on   \n",
              "1361  Showcasing the unique personalities of small h...  \n",
              "1362  Straight from James Fenimore Cooper’s novel, L...  \n",
              "1363                                                     \n",
              "1364  The headline reads: \"2012 Reserve Cabernet - R...  \n",
              "\n",
              "[1347 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b883f042-f9b4-4255-8c04-c8a5b433fcfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>region</th>\n",
              "      <th>variety</th>\n",
              "      <th>rating</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3 Rings Reserve Shiraz 2004</td>\n",
              "      <td>Barossa Valley, Barossa, South Australia, Aust...</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Vintage Comments : Classic Barossa vintage con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abreu Vineyards Cappella 2007</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Cappella is a proprietary blend of two clones ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abreu Vineyards Cappella 2010</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>98.0</td>\n",
              "      <td>Cappella is one of the oldest vineyard sites i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abreu Vineyards Howell Mountain 2008</td>\n",
              "      <td>Howell Mountain, Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>When David purchased this Howell Mountain prop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abreu Vineyards Howell Mountain 2009</td>\n",
              "      <td>Howell Mountain, Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>98.0</td>\n",
              "      <td>As a set of wines, it is hard to surpass the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1360</th>\n",
              "      <td>Lewis Cellars Alec's Blend Red 2002</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Number 12 on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>Lewis Cellars Cabernet Sauvignon 2002</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Showcasing the unique personalities of small h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362</th>\n",
              "      <td>Lewis Cellars Cuvee L Cabernet Sauvignon 2015</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Straight from James Fenimore Cooper’s novel, L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1363</th>\n",
              "      <td>Lewis Cellars Reserve Cabernet Sauvignon 2010</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>Lewis Cellars Reserve Cabernet Sauvignon (scuf...</td>\n",
              "      <td>Napa Valley, California</td>\n",
              "      <td>Red Wine</td>\n",
              "      <td>96.0</td>\n",
              "      <td>The headline reads: \"2012 Reserve Cabernet - R...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1347 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b883f042-f9b4-4255-8c04-c8a5b433fcfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b883f042-f9b4-4255-8c04-c8a5b433fcfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b883f042-f9b4-4255-8c04-c8a5b433fcfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4f0ce22-0cf6-41fe-a76d-d837e19d4833\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4f0ce22-0cf6-41fe-a76d-d837e19d4833')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4f0ce22-0cf6-41fe-a76d-d837e19d4833 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9228c6c4-b1a7-407e-964f-039f90b868c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9228c6c4-b1a7-407e-964f-039f90b868c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1347,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1343,\n        \"samples\": [\n          \"Domaine de Beaurenard Cuvee Boisrenard Chateauneuf-du-Pape 2017\",\n          \"Chateau Lynch-Bages 6-Pack OWC (Futures Pre-Sale) 2019\",\n          \"Chateau Clinet (6-Pack OWC Futures Pre-Sale) 2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 123,\n        \"samples\": [\n          \"Chateauneuf-du-Pape, Rhone, France\",\n          \"Ribera del Duero, Spain\",\n          \"Aloxe-Corton, Cote de Beaune, Cote d'Or, Burgundy, France\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variety\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"White Wine\",\n          \"Sparkling & Champagne\",\n          \"Collectible\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9982152360769972,\n        \"min\": 96.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          98.0,\n          97.0,\n          96.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1092,\n        \"samples\": [\n          \"Blend: 71% Cabernet Sauvignon, 23% Merlot, 5% Cabernet Franc, 1% Petit Verdot\",\n          \"Winemaker Thibaut Delmotte has crafted wines of distinction and international acclaim for Colome. He believes the Malbec from Altura Maxima Vineyard is the embodiment of two extremes - a traditional grape variety from his French origins made from the vineyard that challenges all convention in the modern viticultural world.\",\n          \"The inaugural 2017 Powder House Chardonnay makes a powerful debut with captivating aromas of ripe peach, green apple, lime powder, and candied lemon peel. The palate is intense and concentrated with lemon cream, citrus spice, and a savory note. This wine is full-bodied and complex with a precision acid backbone leading to a long and persistent finish. There is a healthy greenish hue on the edge of the glass. The wine is slightly hazy showing our commitment to minimal intervention winemaking.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "yuqhme7LK-iY"
      },
      "id": "yuqhme7LK-iY",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = SentenceTransformer('all-MiniLM-L6-v2') # Model to create embeddings"
      ],
      "metadata": {
        "id": "6HiCojvyLB9w"
      },
      "id": "6HiCojvyLB9w",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance"
      ],
      "metadata": {
        "id": "hA8Kv0LPLEMQ"
      },
      "id": "hA8Kv0LPLEMQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant.recreate_collection(\n",
        "    collection_name=\"top_wines\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd1WAaJgLG-P",
        "outputId": "844d45dc-b6f4-4332-88fb-1a979604bf11"
      },
      "id": "sd1WAaJgLG-P",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-eefb947fdd31>:1: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant.recreate_collection(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant.upload_points(\n",
        "    collection_name=\"top_wines\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"notes\"]).tolist(),\n",
        "            payload=doc\n",
        "        ) for idx, doc in enumerate(data) # data is the variable holding all the wines\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "jQpY10iPLJGA"
      },
      "id": "jQpY10iPLJGA",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hits = qdrant.search(\n",
        "    collection_name=\"top_wines\",\n",
        "    query_vector=encoder.encode(\"99 points Cabernet Sauvignon from Napa Valley\").tolist(),\n",
        "    limit=3\n",
        ")\n",
        "for hit in hits:\n",
        "  print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOe_CCZZLME4",
        "outputId": "be49aca5-ec9f-4e8f-b6f1-817ae17220e6"
      },
      "id": "fOe_CCZZLME4",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Kapcsandy Family Winery State Lane Cabernet Sauvignon Grand Vin 2017', 'region': 'Yountville, Napa Valley, California', 'variety': 'Red Wine', 'rating': 96.0, 'notes': '100% Cabernet Sauvignon'} score: 0.7492028166137619\n",
            "{'name': 'Lewis Cellars Cabernet Sauvignon 2002', 'region': 'Napa Valley, California', 'variety': 'Red Wine', 'rating': 96.0, 'notes': 'Showcasing the unique personalities of small hillside vineyards from Pritchard Hill, Oakville and Rutherford, the 2002 Napa Valley Cabernet delivers compelling aromas of mocha, ripe berries, tobacco and sweet oak spice. The wine is 100% Cabernet Sauvignon, complex, rich and focused. With a deep core of black fruit and traces of briar and vanilla, it turns chocolaty and long on the palate with serious, integrated tannins.'} score: 0.7331372908744138\n",
            "{'name': 'Anakota Helena Montana Vineyard Cabernet Sauvignon 2013', 'region': 'Knights Valley, Sonoma County, California', 'variety': 'Red Wine', 'rating': 96.0, 'notes': 'Blend: 100% Cabernet Sauvignon'} score: 0.7289792858955008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dn1TyJktMDFo"
      },
      "id": "Dn1TyJktMDFo"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Data to be written to the CSV file\n",
        "data = [\n",
        "    {\"Inventor\": \"Thomas Edison\", \"Invention\": \"Light Bulb\"},\n",
        "    {\"Inventor\": \"Alexander Graham Bell\", \"Invention\": \"Telephone\"},\n",
        "    {\"Inventor\": \"Nikola Tesla\", \"Invention\": \"Alternating Current\"},\n",
        "    {\"Inventor\": \"Galileo Galilei\", \"Invention\": \"Telescope\"},\n",
        "    {\"Inventor\": \"Louis Pasteur\", \"Invention\": \"Vaccination\"},\n",
        "    {\"Inventor\": \"Guglielmo Marconi\", \"Invention\": \"Radio\"},\n",
        "    {\"Inventor\": \"Wright Brothers\", \"Invention\": \"Airplane\"},\n",
        "    {\"Inventor\": \"Tim Berners-Lee\", \"Invention\": \"World Wide Web\"},\n",
        "    {\"Inventor\": \"Steve Jobs\", \"Invention\": \"iPhone\"},\n",
        "    {\"Inventor\": \"Bill Gates\", \"Invention\": \"Microsoft Windows\"}\n",
        "]\n",
        "\n",
        "# Name of the CSV file to be created\n",
        "filename = \"inventors_and_inventions.csv\"\n",
        "\n",
        "# Writing data to the CSV file\n",
        "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=[\"Inventor\", \"Invention\"])\n",
        "\n",
        "    # Write the header (column names)\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in data:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(f\"File {filename} has been created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikHsHdtnMg6o",
        "outputId": "6831902c-56ad-4264-bac1-dc71a7e610f0"
      },
      "id": "ikHsHdtnMg6o",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File inventors_and_inventions.csv has been created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kS5F2xpbMqKn"
      },
      "id": "kS5F2xpbMqKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7AfP9DMMqJE"
      },
      "id": "L7AfP9DMMqJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjYaYm-bMqHn"
      },
      "id": "BjYaYm-bMqHn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQxoNdnCMqEZ"
      },
      "id": "BQxoNdnCMqEZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dp4nZ3_UMqBI"
      },
      "id": "Dp4nZ3_UMqBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2') # Model to create embeddings\n",
        "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance\n",
        "qdrant.recreate_collection(\n",
        "    collection_name=\"top_wines\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")\n",
        "qdrant.upload_points(\n",
        "    collection_name=\"top_wines\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"notes\"]).tolist(),\n",
        "            payload=doc\n",
        "        ) for idx, doc in enumerate(data) # data is the variable holding all the wines\n",
        "    ]\n",
        ")\n",
        "hits = qdrant.search(\n",
        "    collection_name=\"top_wines\",\n",
        "    query_vector=encoder.encode(\"99 points Cabernet Sauvignon from Napa Valley\").tolist(),\n",
        "    limit=3\n",
        ")\n",
        "for hit in hits:\n",
        "  print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "id": "dKpQ4s_dMqzS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "dKpQ4s_dMqzS"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQckxREHNeJf"
      },
      "id": "YQckxREHNeJf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "نعم، في الكود الذي كتبته:\n",
        "\n",
        "```python\n",
        "vector=encoder.encode(doc[\"Invention\"]).tolist()\n",
        "```\n",
        "\n",
        "`\"Invention\"` هو اسم العمود في ملف CSV الذي يحتوي على نص الاختراع. هذا يعني أن الكود يتوقع أن يكون لديك عمود في ملف CSV باسم `Invention`، وسيتم استخدام النص الموجود في هذا العمود لإنشاء التضمينات (embeddings) باستخدام النموذج `SentenceTransformer`.\n",
        "\n",
        "### إذا كان اسم العمود مختلفًا:\n",
        "إذا كان اسم العمود في ملف CSV الخاص بك مختلفًا (على سبيل المثال، `اختراع` أو `invention_text`)، فستحتاج إلى تعديل الكود ليعكس الاسم الصحيح للعمود. على سبيل المثال:\n",
        "\n",
        "```python\n",
        "vector=encoder.encode(doc[\"اختراع\"]).tolist()  # إذا كان اسم العمود \"اختراع\"\n",
        "```\n",
        "\n",
        "أو:\n",
        "\n",
        "```python\n",
        "vector=encoder.encode(doc[\"invention_text\"]).tolist()  # إذا كان اسم العمود \"invention_text\"\n",
        "```\n",
        "\n",
        "### مثال لملف CSV مع أعمدة مختلفة:\n",
        "إذا كان ملف CSV الخاص بك يحتوي على أعمدة مثل `اسم المخترع` و`اختراع`، فسيبدو كالتالي:\n",
        "\n",
        "```\n",
        "اسم المخترع,اختراع\n",
        "توماس إديسون,المصباح الكهربائي\n",
        "ألكسندر جراهام بيل,الهاتف\n",
        "نيكولا تيسلا,التيار المتردد\n",
        "```\n",
        "\n",
        "في هذه الحالة، ستحتاج إلى تعديل الكود ليكون:\n",
        "\n",
        "```python\n",
        "vector=encoder.encode(doc[\"اختراع\"]).tolist()  # استخدام العمود \"اختراع\"\n",
        "```\n",
        "\n",
        "### الكود المعدل مع أسماء أعمدة مختلفة:\n",
        "إذا كانت أسماء الأعمدة في ملف CSV هي `اسم المخترع` و`اختراع`، فإليك الكود المعدل:\n",
        "\n",
        "```python\n",
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import csv\n",
        "\n",
        "# تهيئة نموذج التشفير\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# إنشاء مثيل Qdrant في الذاكرة\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "# إعادة إنشاء المجموعة (collection) للمخترعين\n",
        "qdrant.recreate_collection(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(),\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "# مسار ملف CSV\n",
        "data_path = \"inventors.csv\"  # تأكد من أن الملف موجود في نفس الدليل أو قم بتحديد المسار الكامل\n",
        "\n",
        "# قراءة البيانات من ملف CSV\n",
        "data = []\n",
        "with open(data_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)  # قراءة الملف كقاموس\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "# تحميل النقاط (المخترعين واختراعاتهم) إلى مجموعة Qdrant\n",
        "qdrant.upload_points(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"اختراع\"]).tolist(),  # استخدام العمود \"اختراع\"\n",
        "            payload=doc\n",
        "        ) for idx, doc in enumerate(data)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# البحث عن اختراعات مشابهة بناءً على استعلام\n",
        "query = \"جهاز ينتج الضوء\"  # مثال لاستعلام\n",
        "hits = qdrant.search(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    query_vector=encoder.encode(query).tolist(),  # تشفير الاستعلام\n",
        "    limit=3  # تحديد عدد النتائج\n",
        ")\n",
        "\n",
        "# طباعة نتائج البحث\n",
        "for hit in hits:\n",
        "    print(hit.payload, \"score:\", hit.score)\n",
        "```\n",
        "\n",
        "### ملاحظة:\n",
        "- تأكد من أن أسماء الأعمدة في الكود تتطابق مع أسماء الأعمدة في ملف CSV.\n",
        "- إذا كان ملف CSV يحتوي على رأس (header)، فسيتم استخدامه تلقائيًا عند قراءة الملف باستخدام `csv.DictReader`."
      ],
      "metadata": {
        "id": "RteiGm_xOmjH"
      },
      "id": "RteiGm_xOmjH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "Lsxu15BMOueH"
      },
      "id": "Lsxu15BMOueH"
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import csv\n",
        "\n",
        "# تهيئة نموذج التشفير\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')  # نموذج لإنشاء التضمينات\n",
        "\n",
        "# إنشاء مثيل Qdrant في الذاكرة\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "# إعادة إنشاء المجموعة (collection) للمخترعين\n",
        "qdrant.recreate_collection(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(),  # حجم المتجهات يعتمد على النموذج\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "# مسار ملف CSV الذي يحتوي على البيانات\n",
        "data_path = \"/content/inventors_and_inventions.csv\"  # تأكد من أن الملف موجود في نفس الدليل أو قم بتحديد المسار الكامل\n",
        "\n",
        "# قراءة البيانات من ملف CSV\n",
        "data = []\n",
        "with open(data_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)  # قراءة الملف كقاموس\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "# تحميل النقاط (المخترعين واختراعاتهم) إلى مجموعة Qdrant\n",
        "qdrant.upload_points(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"Invention\"]).tolist(),  # تشفير نص الاختراع\n",
        "            payload=doc\n",
        "        ) for idx, doc in enumerate(data)  # البيانات مخزنة في المتغير data\n",
        "    ]\n",
        ")\n",
        "\n",
        "# البحث عن اختراعات مشابهة بناءً على استعلام\n",
        "query = \"A device that produces light\"  # مثال لاستعلام\n",
        "hits = qdrant.search(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    query_vector=encoder.encode(query).tolist(),  # تشفير الاستعلام\n",
        "    limit=1  # تحديد عدد النتائج\n",
        ")\n",
        "\n",
        "# طباعة نتائج البحث\n",
        "for hit in hits:\n",
        "    print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYzBWk1ZNa9n",
        "outputId": "18d1446f-16b2-44e6-dd36-9565f3c6e7aa"
      },
      "id": "RYzBWk1ZNa9n",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-649dc56ff0de>:12: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant.recreate_collection(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Inventor': 'Thomas Edison', 'Invention': 'Light Bulb'} score: 0.632008530571912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nCMc0RvzOILq"
      },
      "id": "nCMc0RvzOILq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/inventors_and_inventions.csv\"\n",
        "\n",
        "collection_name=\"inventors_and_inventions\",\n",
        "\n"
      ],
      "metadata": {
        "id": "nRuTH82kOIIP"
      },
      "id": "nRuTH82kOIIP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUi7al6TOIEY"
      },
      "id": "qUi7al6TOIEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9G6055gOIA3"
      },
      "id": "F9G6055gOIA3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize the encoder model\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')  # Model to create embeddings\n",
        "\n",
        "# Create an in-memory Qdrant instance\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "# Recreate the collection for inventors\n",
        "qdrant.recreate_collection(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(),  # Vector size is defined by the model\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "# Data for inventors and their inventions\n",
        "data = [\n",
        "    {\"Inventor\": \"Thomas Edison\", \"Invention\": \"Light Bulb\"},\n",
        "    {\"Inventor\": \"Alexander Graham Bell\", \"Invention\": \"Telephone\"},\n",
        "    {\"Inventor\": \"Nikola Tesla\", \"Invention\": \"Alternating Current\"},\n",
        "    {\"Inventor\": \"Galileo Galilei\", \"Invention\": \"Telescope\"},\n",
        "    {\"Inventor\": \"Louis Pasteur\", \"Invention\": \"Vaccination\"},\n",
        "    {\"Inventor\": \"Guglielmo Marconi\", \"Invention\": \"Radio\"},\n",
        "    {\"Inventor\": \"Wright Brothers\", \"Invention\": \"Airplane\"},\n",
        "    {\"Inventor\": \"Tim Berners-Lee\", \"Invention\": \"World Wide Web\"},\n",
        "    {\"Inventor\": \"Steve Jobs\", \"Invention\": \"iPhone\"},\n",
        "    {\"Inventor\": \"Bill Gates\", \"Invention\": \"Microsoft Windows\"}\n",
        "]\n",
        "\n",
        "# Upload points (inventors and inventions) to the Qdrant collection\n",
        "qdrant.upload_points(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"Invention\"]).tolist(),  # Encode the invention text\n",
        "            payload=doc\n",
        "        ) for idx, doc in enumerate(data)  # data is the variable holding all the inventors\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Search for similar inventions based on a query\n",
        "query = \"A device that produces light\"  # Example query\n",
        "hits = qdrant.search(\n",
        "    collection_name=\"inventors_and_inventions\",\n",
        "    query_vector=encoder.encode(query).tolist(),  # Encode the query\n",
        "    limit=3  # Limit the number of results\n",
        ")\n",
        "\n",
        "# Print the search results\n",
        "for hit in hits:\n",
        "    print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU-CC8lGM-X3",
        "outputId": "04d14174-7dc9-4555-a454-d0225632628e"
      },
      "id": "PU-CC8lGM-X3",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-54e9162d9f8f>:11: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant.recreate_collection(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Inventor': 'Thomas Edison', 'Invention': 'Light Bulb'} score: 0.632008530571912\n",
            "{'Inventor': 'Galileo Galilei', 'Invention': 'Telescope'} score: 0.37578558618623886\n",
            "{'Inventor': 'Steve Jobs', 'Invention': 'iPhone'} score: 0.2843923830227583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTMv2ZSBOzmu"
      },
      "id": "lTMv2ZSBOzmu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHFSNiTwOzjh"
      },
      "id": "MHFSNiTwOzjh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/valentij/test.csv/resolve/main/nn_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKL_UfB0OzdH",
        "outputId": "2267cf49-dfed-40a0-dbc8-c046dd225a0a"
      },
      "id": "pKL_UfB0OzdH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 23:04:32--  https://huggingface.co/datasets/valentij/test.csv/resolve/main/nn_test.csv\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.12, 3.165.160.11, 3.165.160.61, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/c5/d2/c5d2041977986f42917562e9e6d8514be8b3bf15869688ea5ebc672f95bdbbee/91e43ece29fa39ad2e625cb4b31c123e5cd690f99bfe03c3546ea59fe20e393f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27nn_test.csv%3B+filename%3D%22nn_test.csv%22%3B&response-content-type=text%2Fcsv&Expires=1737590672&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzU5MDY3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jNS9kMi9jNWQyMDQxOTc3OTg2ZjQyOTE3NTYyZTllNmQ4NTE0YmU4YjNiZjE1ODY5Njg4ZWE1ZWJjNjcyZjk1YmRiYmVlLzkxZTQzZWNlMjlmYTM5YWQyZTYyNWNiNGIzMWMxMjNlNWNkNjkwZjk5YmZlMDNjMzU0NmVhNTlmZTIwZTM5M2Y%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=fOABP7aeN%7ENTIJvJY5Hyljyl-mDdJgOTcIid56AlgGh3JWaTBeKOtPWkuw6wi%7EOoh6sO8HXd9m4OPr5lHyEDFDORlME0zUDDu3yWR%7E-ces7glK-YSekMsGTc7O%7EpZjejHcE0D1n%7ElLCJu5k3nlrJpGF418h9hVUtLN6U7e0eTQbLJMrTC1Rr9V%7Ew%7ERSjGtgi2yLU3zGKl1VEsKpQBczyQEGxRAQrFsAg2A-kTVvFLYSL2zIwfuG4XWjhGizFcZTUQUuaDJbM0IzRD-URwOdLzZj9BTEaj4fCscc2U3zFk52oOxkiJM8Rqd%7EGLsaiMjnffyax2CPDZJMBA%7EI9v0Fazg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-01-22 23:04:32--  https://cdn-lfs.hf.co/repos/c5/d2/c5d2041977986f42917562e9e6d8514be8b3bf15869688ea5ebc672f95bdbbee/91e43ece29fa39ad2e625cb4b31c123e5cd690f99bfe03c3546ea59fe20e393f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27nn_test.csv%3B+filename%3D%22nn_test.csv%22%3B&response-content-type=text%2Fcsv&Expires=1737590672&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzU5MDY3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jNS9kMi9jNWQyMDQxOTc3OTg2ZjQyOTE3NTYyZTllNmQ4NTE0YmU4YjNiZjE1ODY5Njg4ZWE1ZWJjNjcyZjk1YmRiYmVlLzkxZTQzZWNlMjlmYTM5YWQyZTYyNWNiNGIzMWMxMjNlNWNkNjkwZjk5YmZlMDNjMzU0NmVhNTlmZTIwZTM5M2Y%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=fOABP7aeN%7ENTIJvJY5Hyljyl-mDdJgOTcIid56AlgGh3JWaTBeKOtPWkuw6wi%7EOoh6sO8HXd9m4OPr5lHyEDFDORlME0zUDDu3yWR%7E-ces7glK-YSekMsGTc7O%7EpZjejHcE0D1n%7ElLCJu5k3nlrJpGF418h9hVUtLN6U7e0eTQbLJMrTC1Rr9V%7Ew%7ERSjGtgi2yLU3zGKl1VEsKpQBczyQEGxRAQrFsAg2A-kTVvFLYSL2zIwfuG4XWjhGizFcZTUQUuaDJbM0IzRD-URwOdLzZj9BTEaj4fCscc2U3zFk52oOxkiJM8Rqd%7EGLsaiMjnffyax2CPDZJMBA%7EI9v0Fazg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.238.217.120, 18.238.217.113, 18.238.217.81, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.238.217.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25071507 (24M) [text/csv]\n",
            "Saving to: ‘nn_test.csv’\n",
            "\n",
            "nn_test.csv         100%[===================>]  23.91M  46.6MB/s    in 0.5s    \n",
            "\n",
            "2025-01-22 23:04:33 (46.6 MB/s) - ‘nn_test.csv’ saved [25071507/25071507]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxe0Qyh5SWAO"
      },
      "id": "bxe0Qyh5SWAO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/datasets/valentij/test.csv/viewer?row=3"
      ],
      "metadata": {
        "id": "rI2TDVvClFlm"
      },
      "id": "rI2TDVvClFlm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ayhgشغال"
      ],
      "metadata": {
        "id": "3Y1miIPAk_Mo"
      },
      "id": "3Y1miIPAk_Mo"
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import csv\n",
        "\n",
        "# تهيئة نموذج التشفير\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')  # نموذج لإنشاء التضمينات\n",
        "\n",
        "# إنشاء مثيل Qdrant في الذاكرة\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "# إعادة إنشاء المجموعة (collection) للمخترعين\n",
        "qdrant.recreate_collection(\n",
        "    collection_name=\"nn_test\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=encoder.get_sentence_embedding_dimension(),  # حجم المتجهات يعتمد على النموذج\n",
        "        distance=models.Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "# مسار ملف CSV الذي يحتوي على البيانات\n",
        "data_path = \"/content/nn_test.csv\"  # تأكد من أن الملف موجود في نفس الدليل أو قم بتحديد المسار الكامل\n",
        "\n",
        "# قراءة البيانات من ملف CSV\n",
        "data = []\n",
        "with open(data_path, mode='r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)  # قراءة الملف كقاموس\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "# تحميل النقاط (المخترعين واختراعاتهم) إلى مجموعة Qdrant\n",
        "qdrant.upload_points(\n",
        "    collection_name=\"nn_test\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=encoder.encode(doc[\"text\"]).tolist(),  # تشفير نص الاختراع\n",
        "            payload=doc\n",
        "        ) for idx, doc in enumerate(data)  # البيانات مخزنة في المتغير data\n",
        "    ]\n",
        ")\n",
        "\n",
        "# البحث عن اختراعات مشابهة بناءً على استعلام\n",
        "query = \"What is the medication mentioned in the data that helped treat depression, insomnia and anxiety?\"  # مثال لاستعلام\n",
        "hits = qdrant.search(\n",
        "    collection_name=\"nn_test\",\n",
        "    query_vector=encoder.encode(query).tolist(),  # تشفير الاستعلام\n",
        "    limit=1  # تحديد عدد النتائج\n",
        ")\n",
        "\n",
        "# طباعة نتائج البحث\n",
        "for hit in hits:\n",
        "    print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjuNzcH5OzZP",
        "outputId": "b529f47c-8593-433a-a711-0e165b9268f5"
      },
      "id": "GjuNzcH5OzZP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-96cb74f0b4d6>:12: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant.recreate_collection(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': '\"Excellent medicine for anxiety, depression and insomnia.\"', 'label': '1'} score: 0.8083904173713107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<ipython-input-1-96cb74f0b4d6>:12: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
        "  qdrant.recreate_collection(\n",
        "{'text': '\"Excellent medicine for anxiety, depression and insomnia.\"', 'label': '1'} score: 0.8083904173713107"
      ],
      "metadata": {
        "id": "xyo10C8yksCX"
      },
      "id": "xyo10C8yksCX"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GwpgT_pks5m"
      },
      "id": "2GwpgT_pks5m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "om8Z5R4UzqDS"
      },
      "id": "om8Z5R4UzqDS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_3GwCI1zqAb"
      },
      "id": "M_3GwCI1zqAb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from pymilvus import connections, Collection, CollectionSchema, DataType, FieldSchema, utility\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "snaqmJwQzp9D",
        "outputId": "00ed318e-5d74-436c-a284-3dc23d007abc"
      },
      "id": "snaqmJwQzp9D",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pymilvus'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cd6ff27a8b4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpymilvus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconnections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollectionSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFieldSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyPDF2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDPRContextEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDPRQuestionEncoderTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymilvus'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "956VOYHl0cFj",
        "outputId": "d2450bf9-ee5d-499c-dd29-b65d11b266eb"
      },
      "id": "956VOYHl0cFj",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from qdrant_client import QdrantClient, models  # استبدال PyMilvus بـ Qdrant\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "# تهيئة Qdrant\n",
        "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
        "\n",
        "# ... بقية التعليمات البرمجية ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "NeFVEOTB0Z1L",
        "outputId": "e9e9eda8-8b52-412c-f7fd-966ee9bc9999"
      },
      "id": "NeFVEOTB0Z1L",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'PyPDF2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b3eefc82a0b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqdrant_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQdrantClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m  \u001b[0;31m# استبدال PyMilvus بـ Qdrant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyPDF2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDPRContextEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDPRQuestionEncoderTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "!pip install faiss-cpu==1.7.4"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugRuySoI0gb0",
        "outputId": "c70ba11e-e49d-4f63-8fd6-c58543f68773"
      },
      "id": "ugRuySoI0gb0",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu==1.7.4\n",
            "  Downloading faiss_cpu-1.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Downloading faiss_cpu-1.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import faiss\n",
        "import numpy as np"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "SmkGBDjQ0gti"
      },
      "id": "SmkGBDjQ0gti",
      "execution_count": 6,
      "outputs": []
    },
    {
      "source": [
        "dimension = 128  # أبعاد متجهاتك\n",
        "index = faiss.IndexFlatL2(dimension)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "c-2P9C8V0hA0"
      },
      "id": "c-2P9C8V0hA0",
      "execution_count": 7,
      "outputs": []
    },
    {
      "source": [
        "data = np.random.rand(1000, dimension).astype('float32')  # مثال لبيانات عشوائية\n",
        "index.add(data)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eaSAVns30hh7"
      },
      "id": "eaSAVns30hh7",
      "execution_count": 8,
      "outputs": []
    },
    {
      "source": [
        "query = np.random.rand(1, dimension).astype('float32')  # استعلام البحث\n",
        "k = 5  # عدد النتائج المراد إرجاعها\n",
        "D, I = index.search(query, k)  # D: المسافات، I: فهارس المتجهات"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9LfiLB610hzU"
      },
      "id": "9LfiLB610hzU",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SP5Hdx_80xLq"
      },
      "id": "SP5Hdx_80xLq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jboothomas.medium.com/rag-and-the-challenge-of-raw-to-embedded-dataset-size-4dbe70722cd2"
      ],
      "metadata": {
        "id": "k1BWYv0Z09OL"
      },
      "id": "k1BWYv0Z09OL"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwiajOVc0xOy"
      },
      "id": "kwiajOVc0xOy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ITc0tJ50xR6"
      },
      "id": "3ITc0tJ50xR6",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import os\n",
        "import torch\n",
        "import faiss  # استيراد Faiss\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "\n",
        "# تحديد أبعاد المتجهات\n",
        "dimension = 768  # افتراض أن أبعاد المتجهات هي 768\n",
        "\n",
        "# إنشاء فهرس Faiss\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# دالة لتحميل بيانات PDF وإنشاء تضمينات\n",
        "def load_and_embed_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "    # إنشاء تضمينات باستخدام DPRContextEncoder\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).pooler_output\n",
        "\n",
        "    # تحويل التضمينات إلى تنسيق NumPy\n",
        "    embeddings = embeddings.cpu().numpy()\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# مثال لتحميل ملف PDF وإضافة التضمينات إلى فهرس Faiss\n",
        "pdf_path = \"your_pdf_file.pdf\"  # استبدل بمسار ملف PDF الخاص بك\n",
        "embeddings = load_and_embed_pdf(pdf_path)\n",
        "index.add(embeddings)\n",
        "\n",
        "# مثال للبحث عن متجهات مشابهة\n",
        "query_embeddings = load_and_embed_pdf(\"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\")  # استبدل بمسار ملف PDF للاستعلام\n",
        "k = 5  # عدد النتائج المراد إرجاعها\n",
        "D, I = index.search(query_embeddings, k)  # D: المسافات، I: فهارس المتجهات\n",
        "\n",
        "# طباعة نتائج البحث\n",
        "print(\"فهارس النتائج:\", I)\n",
        "print(\"المسافات:\", D)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "b4_YdjiM0z60",
        "outputId": "70d3024e-3dd1-47e7-d842-564890956134"
      },
      "id": "b4_YdjiM0z60",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'your_pdf_file.pdf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7be85da658b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# مثال لتحميل ملف PDF وإضافة التضمينات إلى فهرس Faiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"your_pdf_file.pdf\"\u001b[0m  \u001b[0;31m# استبدل بمسار ملف PDF الخاص بك\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_embed_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-7be85da658b9>\u001b[0m in \u001b[0;36mload_and_embed_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# دالة لتحميل بيانات PDF وإنشاء تضمينات\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_embed_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PyPDF2/_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    315\u001b[0m             )\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_pdf_file.pdf'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caRiSxzX1C55"
      },
      "id": "caRiSxzX1C55",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import os\n",
        "import torch\n",
        "import faiss  # استيراد Faiss\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "\n",
        "# تحديد أبعاد المتجهات\n",
        "dimension = 768  # افتراض أن أبعاد المتجهات هي 768\n",
        "\n",
        "# إنشاء فهرس Faiss\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# دالة لتحميل بيانات PDF وإنشاء تضمينات\n",
        "def load_and_embed_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "    # إنشاء تضمينات باستخدام DPRContextEncoder\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).pooler_output\n",
        "\n",
        "    # تحويل التضمينات إلى تنسيق NumPy\n",
        "    embeddings = embeddings.cpu().numpy()\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# مثال لتحميل ملف PDF وإضافة التضمينات إلى فهرس Faiss\n",
        "pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"  # استبدل بمسار ملف PDF الخاص بك\n",
        "embeddings = load_and_embed_pdf(pdf_path)\n",
        "index.add(embeddings)\n",
        "\n",
        "# مثال للبحث عن متجهات مشابهة\n",
        "query_embeddings = load_and_embed_pdf(\"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\")  # استبدل بمسار ملف PDF للاستعلام\n",
        "k = 5  # عدد النتائج المراد إرجاعها\n",
        "D, I = index.search(query_embeddings, k)  # D: المسافات، I: فهارس المتجهات\n",
        "\n",
        "# طباعة نتائج البحث\n",
        "print(\"فهارس النتائج:\", I)\n",
        "print(\"المسافات:\", D)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "-rVBAMI41ILc",
        "outputId": "32a60414-c724-428a-f9a7-7b7f25c2c2a2"
      },
      "id": "-rVBAMI41ILc",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (2382) must match the size of tensor b (512) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e19460b82644>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# مثال لتحميل ملف PDF وإضافة التضمينات إلى فهرس Faiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\u001b[0m  \u001b[0;31m# استبدل بمسار ملف PDF الخاص بك\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_embed_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e19460b82644>\u001b[0m in \u001b[0;36mload_and_embed_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# تحويل التضمينات إلى تنسيق NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/dpr/modeling_dpr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         outputs = self.ctx_encoder(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/dpr/modeling_dpr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     ) -> Union[BaseModelOutputWithPooling, Tuple[Tensor, ...]]:\n\u001b[0;32m--> 180\u001b[0;31m         outputs = self.bert_model(\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2382) must match the size of tensor b (512) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mwttBYGq1k4y"
      },
      "id": "mwttBYGq1k4y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_milvus():\n",
        "    connections.connect(alias=\"default\", host=\"1.2.3.4\", port=\"19530\")\n",
        "    print(\"Connected to Milvus.\")"
      ],
      "metadata": {
        "id": "1MkboUN01k2K"
      },
      "id": "1MkboUN01k2K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import faiss  # استيراد Faiss\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tf5VoYY1kzD",
        "outputId": "713a8058-4e9c-4af0-e831-be564c475aac"
      },
      "id": "-tf5VoYY1kzD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import faiss\n",
        "\n",
        "def connect_to_faiss(dimension=768):\n",
        "    \"\"\"\n",
        "    Creates a Faiss index and returns it.\n",
        "\n",
        "    Args:\n",
        "        dimension: The dimensionality of the vectors to be indexed.\n",
        "\n",
        "    Returns:\n",
        "        A Faiss index.\n",
        "    \"\"\"\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    print(\"Faiss index created.\")\n",
        "    return index"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2tyKkidB2Fbb"
      },
      "id": "2tyKkidB2Fbb",
      "execution_count": 14,
      "outputs": []
    },
    {
      "source": [
        "index = connect_to_faiss()  # إنشاء فهرس Faiss\n",
        "\n",
        "# ... (بقية الكود) ...\n",
        "\n",
        "# إضافة بيانات إلى فهرس Faiss\n",
        "index.add(embeddings)\n",
        "\n",
        "# البحث في فهرس Faiss\n",
        "D, I = index.search(query_embeddings, k)\n",
        "\n",
        "# ... (بقية الكود) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "JnN0cDbM2KXs",
        "outputId": "ef83ade9-5ac3-4bba-e81f-1c063e16267e"
      },
      "id": "JnN0cDbM2KXs",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faiss index created.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embeddings' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5061877c41e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# إضافة بيانات إلى فهرس Faiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# البحث في فهرس Faiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RAG والتحدي المتمثل في حجم مجموعة البيانات الخام إلى المضمن.\n",
        "جبوتوماس\n",
        "جبوتوماس\n",
        "\n",
        "·\n",
        "اتبع\n",
        "\n",
        "وقت القراءة: 8 دقائق\n",
        "·\n",
        "يوليو 22, 2024\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "مع زيادة عمليات نشر RAG المؤسسية ، من المثير للاهتمام دائما معرفة كيفية عمل الأشياء تحت الأغطية. مع وضع ذلك في الاعتبار في \"كيفية التدوين\" ، سأذهب إلى الكود لتضمين أجزاء نصية من الملفات في قاعدة بيانات متجهة والنظر في مساحة التخزين المطلوبة.\n",
        "\n",
        "عند الاستفادة من قاعدة بيانات متجهة لحالة استخدام RAG، نبحث عبر عمليات التضمين استنادا إلى استعلام المستخدم ونرجع النتائج الأكثر صلة. ثم يتم تمرير النص المقترن بهذه النتائج والاستعلام الأولي إلى LLM حتى يتمكن من إنشاء الاستجابة بناء على هذا السياق المحسن.\n",
        "\n",
        "يجب ألا تخزن قاعدة بيانات المتجهات تمثيل المتجه فحسب ، بل يجب أن تخزن أيضا النص الخام المرتبط ، لذلك دعنا نحصل على هذا الإعداد ثم نرى تأثير كمية كبيرة من بيانات المصدر على التخزين المطلوب ل vectorDB.\n",
        "\n",
        "اعداد\n",
        "لدي بالفعل مثيل milvus يعمل داخل مجموعة kubernetes باستخدام Pure Storage Flashblade للواجهة الخلفية S3. تم تثبيت Milvus باستخدام عامل التشغيل Milvus وتم تطبيق values.yaml التالية أثناء نشر المثيل:\n",
        "\n",
        "apiVersion: milvus.io/v1beta1\n",
        "kind: Milvus\n",
        "metadata:\n",
        "  name: jbt-milvus\n",
        "  labels:\n",
        "    app: milvus\n",
        "spec:\n",
        "  mode: cluster # Omit other fields ...\n",
        "  config:\n",
        "    minio:\n",
        "      # your bucket name\n",
        "      bucketName: jbt-milvus\n",
        "      # Optional, config the prefix of the bucket milvus will use\n",
        "      rootPath: milvus/jbt-milvus\n",
        "      useSSL: false\n",
        "  dependencies:\n",
        "    storage:\n",
        "      # enable external object storage\n",
        "      external: true\n",
        "      type: S3 # MinIO | S3\n",
        "      # the endpoint of AWS S3\n",
        "      endpoint: flashblade.purestorage.com\n",
        "      #useSSL: false\n",
        "      # the secret storing the access key and secret key\n",
        "      secretRef: \"jbt-milvus-s3-secret\"\n",
        "لسهولة الاستخدام ، أضفت أيضا خدمة موازنة التحميل للحصول على عنوان IP مرئي من metalLB من محطة العمل الخاصة بي ، وإليك تكوين k8s السريع لذلك:\n",
        "\n",
        "apiVersion: v1\n",
        "kind: Service\n",
        "metadata:\n",
        "  name: jbt-milvus-loadbalancer\n",
        "spec:\n",
        "  type: LoadBalancer\n",
        "  selector:\n",
        "    app.kubernetes.io/component: proxy\n",
        "    app.kubernetes.io/instance: jbt-milvus\n",
        "    app.kubernetes.io/name: milvus\n",
        "    milvus.io/service: \"true\"\n",
        "  ports:\n",
        "    - protocol: TCP\n",
        "      port: 19530\n",
        "      targetPort: 19530\n",
        "يحتوي \"jbt-milvus-s3-secret\" على الوصول إلى S3 ذي الصلة والمفاتيح السرية لحساب كائن S3 ، وإليك تخطيط yaml المطلوب:\n",
        "\n",
        "apiVersion: v1\n",
        "kind: Secret\n",
        "metadata:\n",
        "  name: jbt-milvus-s3-secret\n",
        "type: Opaque\n",
        "stringData:\n",
        "  accesskey: PSFB*****BJEIA\n",
        "  secretkey: A121*****eJOEN\n",
        "يؤدي تطبيق yamls أعلاه إلى تشغيل مثيل milvus يمكن الوصول إليه من خارج مجموعة k8s ، ويجب أن يبدو مشابها لما يلي:\n",
        "\n",
        "NAME                                             READY   STATUS    RESTARTS      AGE   IP               NODE       NOMINATED NODE   READINESS GATES\n",
        "jbt-milvus-etcd-0                                1/1     Running   0             43h   172.168.96.110   jbt-54-k   <none>           <none>\n",
        "jbt-milvus-etcd-1                                1/1     Running   0             45h   172.168.96.151   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-etcd-2                                1/1     Running   0             13d   172.168.96.163   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-milvus-datacoord-764f9475c5-7kjcb     1/1     Running   0             18h   172.168.96.226   jbt-52-k   <none>           <none>\n",
        "jbt-milvus-milvus-datanode-7f899c8c58-7mj5f      1/1     Running   0             18h   172.168.96.241   jbt-52-k   <none>           <none>\n",
        "jbt-milvus-milvus-indexcoord-5b5f8655f-b5qcw     1/1     Running   0             18h   172.168.96.109   jbt-54-k   <none>           <none>\n",
        "jbt-milvus-milvus-indexnode-8d86c6db8-2c5mt      1/1     Running   0             18h   172.168.96.216   jbt-52-k   <none>           <none>\n",
        "jbt-milvus-milvus-proxy-5dcccff4b-chngq          1/1     Running   0             18h   172.168.96.233   jbt-52-k   <none>           <none>\n",
        "jbt-milvus-milvus-querycoord-fff7966b7-gm89l     1/1     Running   1 (38h ago)   38h   172.168.96.189   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-milvus-querynode-0-54f76d6f6f-8cw2g   1/1     Running   0             17h   172.168.96.113   jbt-54-k   <none>           <none>\n",
        "jbt-milvus-milvus-rootcoord-99477cd9f-zm7cp      1/1     Running   0             18h   172.168.96.229   jbt-52-k   <none>           <none>\n",
        "jbt-milvus-pulsar-bookie-0                       1/1     Running   0             28d   172.168.96.49    jbt-53-k   <none>           <none>\n",
        "jbt-milvus-pulsar-bookie-1                       1/1     Running   0             28d   172.168.96.95    jbt-54-k   <none>           <none>\n",
        "jbt-milvus-pulsar-bookie-2                       1/1     Running   0             45h   172.168.96.165   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-pulsar-broker-0                       1/1     Running   0             13d   172.168.96.142   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-pulsar-proxy-0                        1/1     Running   0             23h   172.168.96.230   jbt-52-k   <none>           <none>\n",
        "jbt-milvus-pulsar-recovery-0                     1/1     Running   0             45h   172.168.96.172   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-pulsar-zookeeper-0                    1/1     Running   0             44h   172.168.96.156   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-pulsar-zookeeper-1                    1/1     Running   0             45h   172.168.96.160   jbt-51-k   <none>           <none>\n",
        "jbt-milvus-pulsar-zookeeper-2                    1/1     Running   0             28d   172.168.96.111   jbt-54-k   <none>           <none>\n",
        "داخل دفتر ملاحظات Jupyter ، أقوم بتحميل نواة مثبتة على المتطلبات التالية: pymilvus 2.4.3 و PyPDF2 3.0.1 و torch 2.3.0 و Transformers 4.41.2.\n",
        "\n",
        "رمز\n",
        "تتمثل الخطوة الأولى في تحميل الوحدات النمطية المطلوبة الخاصة بنا الرمز المميز والنموذج:\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from pymilvus import connections, Collection, CollectionSchema, DataType, FieldSchema, utility\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "ثم أقوم بتحديد الوظائف التالية ، الاتصال بقاعدة بيانات milvus الخاصة بنا:\n",
        "\n",
        "def connect_to_milvus():\n",
        "    connections.connect(alias=\"default\", host=\"1.2.3.4\", port=\"19530\")\n",
        "    print(\"Connected to Milvus.\")\n",
        "إنشاء مجموعة milvus ووظيفة لإدخال بياناتنا. هنا أقوم بتعريف المخطط باستخدام المعرف والتضمينات والنص لحقولي:\n",
        "\n",
        "def create_collection(collection_name, dim=768):\n",
        "    exists = utility.has_collection(collection_name)\n",
        "\n",
        "    if not exists:\n",
        "        print(f\"Collection {collection_name} does not exist.\")\n",
        "        fields = [\n",
        "            FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
        "            FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
        "            FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512)\n",
        "        ]\n",
        "        schema = CollectionSchema(fields, description=\"Embedding Collection\")\n",
        "        collection = Collection(name=collection_name, schema=schema)\n",
        "        print(f\"Collection {collection_name} created.\")\n",
        "    else:\n",
        "        collection = Collection(name=collection_name)\n",
        "        print(f\"Collection {collection_name} already exists.\")\n",
        "    return collection\n",
        "def insert_embeddings(collection, embeddings, texts):\n",
        "    data = [embeddings, texts]\n",
        "    ids = collection.insert(data)\n",
        "    collection.flush()\n",
        "    return ids\n",
        "ثم يعمل على استخراج النص من ملفات في مجلد ، وقم بتقطيع النص وترميزه. ملاحظة: إذا كانت لديك اقتراحات حول أفضل طريقة للتعامل مع طول القطعة وحجم البايت للمخطط الفعلي ، فقل:\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # Implement PDF reading here\n",
        "    # Example: Using PyPDF2 (pip install PyPDF2)\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = ''\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "def chunk_text(text, chunk_size=512):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        # Calculate the byte length if the word is added\n",
        "        additional_length = len(word.encode('utf-8')) + (1 if current_chunk else 0)\n",
        "        new_length = current_length + additional_length\n",
        "        if additional_length <= chunk_size:\n",
        "            current_chunk.append(word)\n",
        "            current_length = new_length\n",
        "        else:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "            current_length = len(word.encode('utf-8'))\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "def encode_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.pooler_output.detach().numpy()[0] #assuming single embedding\n",
        "def move_file_to_done(file_name, source_folder, destination_folder):\n",
        "    # Construct full file paths\n",
        "    source_path = os.path.join(source_folder, file_name)\n",
        "    destination_path = os.path.join(destination_folder, file_name)\n",
        "\n",
        "    # Move the file\n",
        "    try:\n",
        "        shutil.move(source_path, destination_path)\n",
        "        print(f'File {file_name} moved to {destination_folder}')\n",
        "    except FileNotFoundError:\n",
        "        print(f'File {file_name} not found in {source_folder}')\n",
        "    except Exception as e:\n",
        "        print(f'Error moving file: {e}')\n",
        "وأخيرا وظيفة لمعالجة الملفات في مجلد:\n",
        "\n",
        "def process_files(in_directory, out_directory, collection):\n",
        "    for filename in os.listdir(in_directory):\n",
        "        if filename.endswith('.pdf'):\n",
        "            print(f\"Processing {filename}.\")\n",
        "            texts = []\n",
        "            embeddings = []\n",
        "            pdf_path = os.path.join(in_directory, filename)\n",
        "            text = extract_text_from_pdf(pdf_path)\n",
        "            text_chunks = chunk_text(text)\n",
        "\n",
        "            for txt_chunk in text_chunks:\n",
        "                embedding = encode_text(txt_chunk)\n",
        "                texts.append(txt_chunk)\n",
        "                embeddings.append(embedding)\n",
        "\n",
        "            ids = insert_embeddings(collection, embeddings, texts)\n",
        "            move_file_to_done(filename, in_directory, out_directory)\n",
        "            print(f\"Inserted {ids.insert_count} embeddings from {filename}.\")\n",
        "\n",
        "        elif filename.endswith('.txt'):\n",
        "            print(f\"Processing {filename}.\")\n",
        "            texts = []\n",
        "            embeddings = []\n",
        "            txt_path = os.path.join(in_directory, filename)\n",
        "            text = extract_text_from_txt(txt_path)\n",
        "            text_chunks = chunk_text(text)\n",
        "\n",
        "            for txt_chunk in text_chunks:\n",
        "                embedding = encode_text(txt_chunk)\n",
        "                texts.append(txt_chunk)\n",
        "                embeddings.append(embedding)\n",
        "\n",
        "            ids = insert_embeddings(collection, embeddings, texts)\n",
        "            move_file_to_done(filename, in_directory, out_directory)\n",
        "            print(f\"Inserted {ids.insert_count} embeddings from {filename}.\")\n",
        "تضمين ملف PDF واحد\n",
        "أقوم بتوصيل وإنشاء مجموعة لتخزين عمليات التضمين الخاصة بي عن طريق تشغيل التعليمات البرمجية التالية:\n",
        "\n",
        "connect_to_milvus()\n",
        "collection_name = \"my_test_rag\"\n",
        "dimension_size = 768\n",
        "collection = create_collection(collection_name, dimension_size)\n",
        "سيعيد هذا:\n",
        "\n",
        "Connected to Milvus.\n",
        "Collection my_test_rag does not exist.\n",
        "Collection my_test_rag created.\n",
        "ثم أقوم بتشغيل معالجة الملفات داخل دليل معين:\n",
        "\n",
        "my_source_directory = './PDFs'\n",
        "my_dest_directory = './donePDFs'\n",
        "\n",
        "process_files(my_source_directory, my_dest_directory, collection)\n",
        "تم تشغيل ملف PDF واحد ، تم إدراج 1523 تضمنا.\n",
        "\n",
        "البحث في قاعدة بيانات المتجهات\n",
        "يمكنني الآن الاستعلام عن قاعدة بيانات المتجهات واسترداد أجزاء النص ذات الصلة:\n",
        "\n",
        "from pymilvus import connections, Collection, utility\n",
        "from transformers import DPRQuestionEncoderTokenizer, DPRQuestionEncoder\n",
        "\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "\n",
        "\n",
        "collection = Collection(name=\"my_test_rag\")\n",
        "# Check if the index already exists, and create if it does not\n",
        "if not collection.has_index():\n",
        "    index_params = {\n",
        "        \"index_type\": \"IVF_FLAT\",\n",
        "        \"params\": {\"nlist\": 100},\n",
        "        \"metric_type\": \"L2\"\n",
        "    }\n",
        "    collection.create_index(field_name=\"embeddings\", index_params=index_params)\n",
        "\n",
        "# Load the collection into memory\n",
        "collection.load()\n",
        "# Prepare a query text and encode it into a vector\n",
        "query_text = \"Flashblade S3 statistics\"\n",
        "inputs = tokenizer(query_text, return_tensors=\"pt\")\n",
        "query_embedding = model(**inputs).pooler_output.detach().numpy()\n",
        "\n",
        "# Convert the embedding to a list of floats\n",
        "query_embedding = query_embedding.tolist()\n",
        "\n",
        "# Perform the search\n",
        "search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\n",
        "results = collection.search(\n",
        "    data=query_embedding,\n",
        "    anns_field=\"embeddings\",\n",
        "    param=search_params,\n",
        "    limit=5,\n",
        "    expr=None,\n",
        "    output_fields=[\"text\"]\n",
        ")\n",
        "# Print the search results\n",
        "for result in results:\n",
        "    for hit in result:\n",
        "        print(f\"ID: {hit.id}, Score: {hit.distance}, Text: {hit.entity.get('text')}\")\n",
        "سيتم استرداد أجزاء النص المطابقة، على سبيل المثال:\n",
        "\n",
        "ID: 450165976472778458, Score: 95.83973693847656,\n",
        "Text: Hover over any part of a chart to display values for a specific point\n",
        "in time. The values that appear in the point-in-time tooltips are rounded to\n",
        " two decimal places. The Performance Chart The following example displays\n",
        "the IOPS statistics on the array at precisely 5:00:00 on March 12 . The\n",
        "Performance panel includes the Latency, IOPS, and Bandwidth charts. Latency\n",
        " The Latency chart displays the average latency times for various operations.\n",
        " •Read Latency (R)\n",
        "...\n",
        "تضمين آلاف المستندات\n",
        "إذن ماذا يحدث عندما أقوم بإنشاء مجموعة تستند إلى عدة جيجابايت من الملفات النصية؟\n",
        "\n",
        "لهذا قمت بتنزيل 19101 ملف نصي من مشروع Gutenberg بحجم أولي إجمالي يبلغ 7.1 جيجابايت. باستخدام الكود أعلاه ، تم استيعاب مجموعة البيانات هذه في قاعدة بيانات المتجهات مما أدى إلى ما يزيد قليلا عن 14 مليون تضمين. يتم الحصول على العدد النهائي للكيانات في المجموعة باستخدام:\n",
        "\n",
        "from pymilvus import connections, Collection, utility\n",
        "# Connect to Milvus\n",
        "connections.connect(\"default\", host=\"1.2.3.4\", port=\"19530\")\n",
        "\n",
        "collection_name = \"my_test_rag\"\n",
        "collection = Collection(name=collection_name)\n",
        "# Get the number of entities in the collection\n",
        "num_entities = collection.num_entities\n",
        "print(f\"The number of entities in the collection '{collection_name}' is: {num_entities}\")\n",
        "نتيجة:\n",
        "\n",
        "The number of entities in the collection 'my_test_rag' is: 14379441\n",
        "الآن يقوم Milvus بإنشاء كائنات index_files و insert_log و stats_log. انتظرت تشغيل كل insert_logs في index_files وتشغيل الضغط و gc العميق على منصة Milvus للحصول على حجم التخزين النهائي لقاعدة البيانات. للحصول على إجمالي مساحة التخزين المستخدمة لمجموعتي ، أقوم بإدراج وتلخيص الكائنات التي تم إنشاؤها على طبقة التخزين S3:\n",
        "\n",
        "aws s3 --endpoint-url=http://192.168.40.165 --profile fbstaines03 ls --summarize --human-readable --recursive s3://jbt-milvus/milvus/jbt-milvus/index_files | grep Total\n",
        "Total Objects: 4362\n",
        "   Total Size: 61.0 GiB\n",
        "\n",
        "aws s3 --endpoint-url=http://192.168.40.165 --profile fbstaines03 ls --summarize --human-readable --recursive s3://jbt-milvus/milvus/jbt-milvus/insert_log | grep Total\n",
        "Total Objects: 4030\n",
        "   Total Size: 45.2 GiB\n",
        "لقد شهدنا زيادة قدرها 8 أضعاف (أو 15 ضعفا إذا أخذنا في الاعتبار جميع ملفات سجل ديسيبل) في التخزين المطلوبة من مجموعة بيانات النص الأولي إلى إصدار قاعدة البيانات المتجه والمجزأ.\n",
        "\n",
        "جانب آخر ملحوظ هو حقيقة أنه أثناء الاستيعاب ، ينمو حجم قاعدة البيانات إلى عدة أضعاف النتيجة النهائية! ويرجع ذلك إلى استيعاب البيانات في insert_log () ثم يتم تشغيلها في index_logs مع الضغط والضغط وجمع القمامة مما يساعد على تقليل مساحة التخزين التي تتطلبها قاعدة البيانات. خلال الاختبار أعلاه ، نمت قاعدة بياناتي إلى عدة مئات من الجيبي بايت ، أي عدة أضعاف الحجم الإجمالي الفعلي للنهاية. وفقا لقطة الشاشة التالية حيث أخذت قياسات لتطور استخدام تخزين S3 الخلفي على مدار عدة ساعات:\n",
        "\n",
        "\n",
        "مثال على تذبذب مساحة تخزين Milvus S3 المستخدمة\n",
        "استنتاج\n",
        "يتضمن عبء عمل قاعدة بيانات متجهات المؤسسة ما يلي:\n",
        "\n",
        "زيادة مساحة التخزين من البيانات الأولية إلى المتجهات في قاعدة البيانات\n",
        "الحجم المتقلب أثناء استيعاب قاعدة بيانات vector\n",
        "الاستيعاب المتكرر للحفاظ على معرفة المجال المحدثة القابلة للبحث\n",
        "تعد منصة التخزين المبنية على البساطة والأداء المتسق وقابلية التوسع أمرا أساسيا عند التفكير في حالة استخدام RAG للمؤسسات ، فإننا نميل إلى نسيان أنه ليس كل شيء يتعلق بوحدة معالجة الرسومات!"
      ],
      "metadata": {
        "id": "deJfiO8I2la6"
      },
      "id": "deJfiO8I2la6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-QncYhw3lrL"
      },
      "id": "x-QncYhw3lrL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@"
      ],
      "metadata": {
        "id": "jdZF0V0h3mEw"
      },
      "id": "jdZF0V0h3mEw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "للبحث عن النصوص الأكثر صلة باستعلام معين:"
      ],
      "metadata": {
        "id": "7uoaXXO93kWO"
      },
      "id": "7uoaXXO93kWO"
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "_geysVTY3KbR"
      },
      "id": "_geysVTY3KbR",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "e2669a7f4fd0459aaa0947a95b62c8d9",
            "393a43337cd84940baa6fae2a6c2fb06",
            "b75f6717216d4fb3acf78da8dae2e31e",
            "d100ef7008ff476c8d19e4fa526408c3",
            "5e2228bcf86d422487ba866e6f26918e",
            "7ac444d6a5094859a0d9ca64794cf167",
            "70df2429efeb4969866f2b5e5ef6bf3b",
            "a108055b866849fb834c4a15c13bb980",
            "2a083248243d446e835c9317f1ffb55d",
            "b9edc2c0b16245e1af696f5ea79cbc1f",
            "bd55711ddfdb413d90c5521a49df0d76",
            "21f10ff21631456a9fa15eada44e6b90",
            "8001e002442d4d3191ca0faff38bb909",
            "9cf6d221d6d2407097f06c19db8e5dcf",
            "e0e9615d16c5468bbce612fc726e46b1",
            "df91e21893b949afa41f56e3e9b4e4bb",
            "ca2f3729c48f4d7abc4fe62a2272955b",
            "926683b60a944330b16780430c2cfef6",
            "f90dae032fc84ccaa0b9bd1d36b2b6be",
            "205804a230f342c6b2bc9d60a572f16d",
            "9e2391a2155748bc8a892cffffb56741",
            "a317c4152a0f4651a12ae53a1ad3c626",
            "2365be37ae5a41a7930435d91d2b9fe1",
            "234dad56005344d59289b124c75ac6ad",
            "9333a214f49b43c6ba44e3974a98c902",
            "c59386e789124f36b163be9fb9ec917f",
            "9c01ba895e584555b43c9c64fa196f49",
            "73b996e5cdce4eac8ba69fa0f508416b",
            "9b8bb9d0e981443e884a6782ea725f95",
            "fd8eef7df5ae4988bfe2c6f5330c8007",
            "764f2b60e79f414ca8dee60142dc259c",
            "fac043e7fc9b446fb6ec0fe91ba013d5",
            "9fc57f979b5843938484f2dbe7297f40",
            "d102272ccec64321ab3ff2ed7fdae24f",
            "cd257bad79af428d9da667d90d2592b7",
            "1b20fa604fbd4e04b272e8d2ce20bc10",
            "abb9250e525f40e7bd09e933934fddde",
            "02f22386eb2e414bb94294391cd5ce2b",
            "4923934eae9d45a5942742afb99ad431",
            "0ff07ea06d094807add3ea669500c659",
            "9efe56965a5e4ed4a5c84e705144aab6",
            "eb083cf52fcd4c7ba8f4e5c8705f3f87",
            "dce4d9065da24331bb5631d2aa3a02c1",
            "ab98421aacc4463f97472b3a0b5a6f47",
            "77ff1b0c856747eeab9d9d93992a290d",
            "14483e0574df4e67aa7cab42f16feb06",
            "9622ba4b868244a1819362da5be397ad",
            "fb881a0f97454918b8b27641d74ae673",
            "5179088bfc074c2682995eecee1d1707",
            "d8ac7467ca614960899ea1b9e57c02c2",
            "4c3ae808e3f74cb39c381286e630dc40",
            "3fafc2de24a9493fab4c6fdaf112aa9f",
            "29df1193fd4f486894852a599960c302",
            "629915ec289146ecaef60e29b33933ad",
            "c5259f02f4704c80a3027583a10d1be8",
            "fa6598ce2fef4cb2b1a5f464f5fd26cb",
            "fdc5cf4b35ac493091d1f828eda6046f",
            "f28a35dd8b1847d881c0d713f1625d0d",
            "fec3786d9a344fab8c9ba9575ea15cec",
            "1da56b3aa79e445d89280adb163a8bae",
            "9da0b60984d847b6933b96c5904ba5ef",
            "f6247dc919bd4a7a94be5952a296ec55",
            "84e12a0ee173470f9c58e3bd14458699",
            "9ec35ec9f0654f85b33c7a5eeff07637",
            "f0ea7d4ef7ec4f80addde8979317fcd3",
            "8cc844de153b4933be5eb1f122cecf4a"
          ]
        },
        "id": "QkKXfklm3Ndl",
        "outputId": "37de7eb4-8238-4829-f65f-a0a9d15fc09b"
      },
      "id": "QkKXfklm3Ndl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2669a7f4fd0459aaa0947a95b62c8d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21f10ff21631456a9fa15eada44e6b90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2365be37ae5a41a7930435d91d2b9fe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d102272ccec64321ab3ff2ed7fdae24f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77ff1b0c856747eeab9d9d93992a290d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa6598ce2fef4cb2b1a5f464f5fd26cb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# إعداد الفهرس\n",
        "embedding_dim = 384  # حجم التضمين من النموذج\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 هو معيار المسافة\n",
        "\n",
        "# قائمة التضمينات والنصوص المرتبطة بها\n",
        "embeddings = []\n",
        "texts = []\n",
        "\n",
        "# مثال على إضافة نصوص وتضميناتها إلى الفهرس\n",
        "def add_to_faiss(text, index):\n",
        "    embedding = generate_embedding(text)\n",
        "    index.add(np.array([embedding], dtype=\"float32\"))\n",
        "    embeddings.append(embedding)\n",
        "    texts.append(text)\n",
        "\n",
        "# إضافة النصوص\n",
        "add_to_faiss(\"هذا مثال نصي.\", index)\n",
        "add_to_faiss(\"نص آخر للاختبار.\", index)\n"
      ],
      "metadata": {
        "id": "grkljfM43QiK"
      },
      "id": "grkljfM43QiK",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApOIpQpG3RpA"
      },
      "id": "ApOIpQpG3RpA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_in_faiss(query, index, k=5):\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"اختبار النصوص\"\n",
        "results = search_in_faiss(query, index)\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}, Distance: {distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeTKmhv33UQg",
        "outputId": "4fdba406-d429-4849-af0a-c4bdc43c0a6d"
      },
      "id": "QeTKmhv33UQg",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: نص آخر للاختبار., Distance: 3.311124801635742\n",
            "Result: هذا مثال نصي., Distance: 11.12571907043457\n",
            "Result: نص آخر للاختبار., Distance: 3.4028234663852886e+38\n",
            "Result: نص آخر للاختبار., Distance: 3.4028234663852886e+38\n",
            "Result: نص آخر للاختبار., Distance: 3.4028234663852886e+38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "1Zrb3dLt7shc"
      },
      "id": "1Zrb3dLt7shc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### العثور على النصوص المشابهة\n",
        "### مفيد للتعامل مع ملف الداتا"
      ],
      "metadata": {
        "id": "r91L9n6z7i_i"
      },
      "id": "r91L9n6z7i_i"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r76HW8T13Uyg"
      },
      "id": "r76HW8T13Uyg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@"
      ],
      "metadata": {
        "id": "nkqDSqvy3ohB"
      },
      "id": "nkqDSqvy3ohB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال بحث وتطليع نتائج  مكشابهه من النص"
      ],
      "metadata": {
        "id": "lwMuxbe34jba"
      },
      "id": "lwMuxbe34jba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "نتائج عينة:\n",
        "عند تشغيل الكود وإدخال استعلام مثل \"Who is Percy Jackson?\"، ستعرض النتائج نصوصًا من الكتاب متعلقة بالاستعلام."
      ],
      "metadata": {
        "id": "M39uZFvA4XcC"
      },
      "id": "M39uZFvA4XcC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning:\n",
        "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
        "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
        "You will be able to reuse this secret in all of your notebooks.\n",
        "Please note that authentication is recommended but still optional to access public models or datasets.\n",
        "  warnings.warn(\n",
        "Result: this ever happened. But if you recognize yourself in these pages—if you feel something stirring inside—stop reading immediately. You might be one of us. And once you know that, it's only a mat­ ter of time before they sense it too, and they'll come for you. Don't say I didn't warn you. My name is Percy Jackson. I'm twelve years old. Until a few months ago, I was a boarding student at Yancy Academy, a private school for troubled kids in upstate New York. Am I a troubled kid? Yeah. You could say that.\n",
        "Distance: 48.559165954589844\n",
        "\n",
        "Result: Nancy hissed, her face even brighter red than her hair. At least Nancy got packed, too. Mr. Brunner was the only one who ever caught her saying anything wrong. He had radar ears. I thought about his question, and shrugged. \"I don't know, sir.\" \"I see.\" Mr. Brunner looked disappointed. \"Well, half credit, Mr. Jackson. Zeus did indeed feed Kronos a mixture of mustard and wine, which made him disgorge his other five children, who, of course, being immortal gods, had been living and growing up completely\n",
        "Distance: 51.04908752441406\n",
        "\n",
        "Result: eating his kids, right?\" \"Yes,\" Mr. Brunner said, obviously not satisfied. \"And he did this because . . .\" \"Well...\" I racked my brain to remember. \"Kronos was the king god, and—\" \"God?\" Mr. Brunner asked. \"Titan,\" I corrected myself. \"And ... he didn't trust his kids, who were the gods. So, um, Kronos ate them, right? But his wife hid baby Zeus, and gave Kronos a rock to eat instead. And later, when Zeus grew up, he tricked his dad, Kronos, into barfing up his brothers and sisters—\" \"Eeew!\" said\n",
        "Distance: 51.074798583984375\n",
        "\n",
        "Result: snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out louder than I meant it to. The whole group laughed. Mr. Brunner stopped his story. \"Mr. Jackson,\" he said, \"did you have a comment?\" My face was totally red. I said, \"No, sir.\" Mr. Brunner pointed to one of the pictures on the stele. \"Perhaps you'll tell us what this picture represents?\" I looked at the carving, and felt a flush of relief, because I actually recognized it. \"That's Kronos\n",
        "Distance: 51.2169189453125\n",
        "\n",
        "Result: one of the girls behind me. \"—and so there was this big fight between the gods and the Titans,\" I continued, \"and the gods won.\" [5] Some snickers from the group. Behind me, Nancy Bobofit mumbled to a friend, \"Like we're going to use this in real life. Like it's going to say on our job applications, 'Please explain why Kronos ate his kids.' \" \"And why, Mr. Jackson,\" Brunner said, \"to paraphrase Miss Bobofit's excellent question, does this matter in real life?\" \"Busted,\" Grover muttered. \"Shut up,\"\n",
        "Distance: 51.47588348388672"
      ],
      "metadata": {
        "id": "prVmzHP84avS"
      },
      "id": "prVmzHP84avS"
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات الضرورية\n",
        "#!pip install faiss-cpu PyPDF2 transformers\n",
        "\n",
        "# استخراج النصوص من الكتاب باستخدام PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# تحديد مسار الكتاب\n",
        "book_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\n",
        "book_text = extract_text_from_pdf(book_path)\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(text, max_chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    chunk = []\n",
        "    for word in words:\n",
        "        chunk.append(word)\n",
        "        if len(\" \".join(chunk)) > max_chunk_size:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "            chunk = []\n",
        "    if chunk:\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(book_text)\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# إعداد الفهرس\n",
        "embedding_dim = 384  # حجم التضمين من النموذج\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 هو معيار المسافة\n",
        "\n",
        "# إضافة النصوص والتضمينات إلى الفهرس\n",
        "embeddings = []\n",
        "texts = []\n",
        "\n",
        "for chunk in text_chunks:\n",
        "    embedding = generate_embedding(chunk)\n",
        "    index.add(np.array([embedding], dtype=\"float32\"))\n",
        "    embeddings.append(embedding)\n",
        "    texts.append(chunk)\n",
        "\n",
        "# البحث في الكتاب باستخدام Faiss\n",
        "def search_in_faiss(query, index, k=5):\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"Who is Percy Jackson?\"\n",
        "results = search_in_faiss(query, index)\n",
        "\n",
        "# عرض النتائج\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmr_mCdP385i",
        "outputId": "782d0b6a-bb64-46a1-b0ed-121ae30e07b2"
      },
      "id": "dmr_mCdP385i",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: this ever happened. But if you recognize yourself in these pages—if you feel something stirring inside—stop reading immediately. You might be one of us. And once you know that, it's only a mat­ ter of time before they sense it too, and they'll come for you. Don't say I didn't warn you. My name is Percy Jackson. I'm twelve years old. Until a few months ago, I was a boarding student at Yancy Academy, a private school for troubled kids in upstate New York. Am I a troubled kid? Yeah. You could say that.\n",
            "Distance: 48.559165954589844\n",
            "\n",
            "Result: Nancy hissed, her face even brighter red than her hair. At least Nancy got packed, too. Mr. Brunner was the only one who ever caught her saying anything wrong. He had radar ears. I thought about his question, and shrugged. \"I don't know, sir.\" \"I see.\" Mr. Brunner looked disappointed. \"Well, half credit, Mr. Jackson. Zeus did indeed feed Kronos a mixture of mustard and wine, which made him disgorge his other five children, who, of course, being immortal gods, had been living and growing up completely\n",
            "Distance: 51.04908752441406\n",
            "\n",
            "Result: eating his kids, right?\" \"Yes,\" Mr. Brunner said, obviously not satisfied. \"And he did this because . . .\" \"Well...\" I racked my brain to remember. \"Kronos was the king god, and—\" \"God?\" Mr. Brunner asked. \"Titan,\" I corrected myself. \"And ... he didn't trust his kids, who were the gods. So, um, Kronos ate them, right? But his wife hid baby Zeus, and gave Kronos a rock to eat instead. And later, when Zeus grew up, he tricked his dad, Kronos, into barfing up his brothers and sisters—\" \"Eeew!\" said\n",
            "Distance: 51.074798583984375\n",
            "\n",
            "Result: snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out louder than I meant it to. The whole group laughed. Mr. Brunner stopped his story. \"Mr. Jackson,\" he said, \"did you have a comment?\" My face was totally red. I said, \"No, sir.\" Mr. Brunner pointed to one of the pictures on the stele. \"Perhaps you'll tell us what this picture represents?\" I looked at the carving, and felt a flush of relief, because I actually recognized it. \"That's Kronos\n",
            "Distance: 51.2169189453125\n",
            "\n",
            "Result: one of the girls behind me. \"—and so there was this big fight between the gods and the Titans,\" I continued, \"and the gods won.\" [5] Some snickers from the group. Behind me, Nancy Bobofit mumbled to a friend, \"Like we're going to use this in real life. Like it's going to say on our job applications, 'Please explain why Kronos ate his kids.' \" \"And why, Mr. Jackson,\" Brunner said, \"to paraphrase Miss Bobofit's excellent question, does this matter in real life?\" \"Busted,\" Grover muttered. \"Shut up,\"\n",
            "Distance: 51.47588348388672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2laWsuxD5YrC"
      },
      "id": "2laWsuxD5YrC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPKCqZdS5YoR"
      },
      "id": "pPKCqZdS5YoR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sb18NP2-5Ylg"
      },
      "id": "Sb18NP2-5Ylg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "كود تنظيف النصوص"
      ],
      "metadata": {
        "id": "5S1FUsLN5dyb"
      },
      "id": "5S1FUsLN5dyb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "VPx0M9GR5epJ"
      },
      "id": "VPx0M9GR5epJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    وظيفة لتنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    # إزالة الحواشي مثل [1], [5], [A], إلخ.\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "\n",
        "    # إزالة العلامات الخاصة (يمكن تعديلها حسب الحاجة)\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)\n",
        "\n",
        "    # إزالة الأسطر الفارغة أو الزائدة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
        "\n",
        "    # إزالة المسافات الزائدة في بداية ونهاية النص\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# مثال على النصوص:\n",
        "sample_text = \"\"\"\n",
        "[1] My name is Percy Jackson. I'm twelve years old.\n",
        "Until a few months ago, I was at Yancy Academy. [5]\n",
        "\n",
        "---\n",
        "\n",
        "Am I a troubled kid? Yeah. You could say that.\n",
        "\"\"\"\n",
        "\n",
        "# تنظيف النصوص\n",
        "cleaned_text = clean_text(sample_text)\n",
        "print(cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt8ZgFdn5YiN",
        "outputId": "97d2b909-9e0a-447e-909a-581d3fbff906"
      },
      "id": "qt8ZgFdn5YiN",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Percy Jackson. Im twelve years old. \n",
            "Until a few months ago, I was at Yancy Academy. \n",
            "Am I a troubled kid? Yeah. You could say that.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "############################################"
      ],
      "metadata": {
        "id": "rpVNJA__6-HJ"
      },
      "id": "rpVNJA__6-HJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "HEkYN4oO68a5"
      },
      "id": "HEkYN4oO68a5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "الكود الكامل مع تنظيف النصوص"
      ],
      "metadata": {
        "id": "Uxe-tD3J5p9R"
      },
      "id": "Uxe-tD3J5p9R"
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات الضرورية\n",
        "#!pip install faiss-cpu PyPDF2 transformers\n",
        "\n",
        "# استخراج النصوص من الكتاب باستخدام PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# تنظيف النصوص\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    وظيفة لتنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # إزالة الحواشي\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)  # إزالة العلامات الخاصة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # إزالة الأسطر الفارغة\n",
        "    text = text.strip()  # إزالة المسافات الزائدة\n",
        "    return text\n",
        "\n",
        "# تحديد مسار الكتاب\n",
        "book_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\n",
        "book_text = extract_text_from_pdf(book_path)\n",
        "\n",
        "# تنظيف النص المستخرج\n",
        "cleaned_book_text = clean_text(book_text)\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(text, max_chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    chunk = []\n",
        "    for word in words:\n",
        "        chunk.append(word)\n",
        "        if len(\" \".join(chunk)) > max_chunk_size:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "            chunk = []\n",
        "    if chunk:\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(cleaned_book_text)\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# إعداد الفهرس\n",
        "embedding_dim = 384  # حجم التضمين من النموذج\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 هو معيار المسافة\n",
        "\n",
        "# إضافة النصوص والتضمينات إلى الفهرس\n",
        "embeddings = []\n",
        "texts = []\n",
        "\n",
        "for chunk in text_chunks:\n",
        "    embedding = generate_embedding(chunk)\n",
        "    index.add(np.array([embedding], dtype=\"float32\"))\n",
        "    embeddings.append(embedding)\n",
        "    texts.append(chunk)\n",
        "\n",
        "# البحث في الكتاب باستخدام Faiss\n",
        "def search_in_faiss(query, index, k=5):\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"Who is Percy Jackson?\"\n",
        "results = search_in_faiss(query, index)\n",
        "\n",
        "# عرض النتائج\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luus-L335l4S",
        "outputId": "4ae52d48-967f-4af2-b4c5-3bc6a031efdf"
      },
      "id": "luus-L335l4S",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: pagesif you feel something stirring insidestop reading immediately. You might be one of us. And once you know that, its only a mat ter of time before they sense it too, and theyll come for you. Dont say I didnt warn you. My name is Percy Jackson. Im twelve years old. Until a few months ago, I was a boarding student at Yancy Academy, a private school for troubled kids in upstate New York. Am I a troubled kid? Yeah. You could say that. I could start at any point in my short miserable life to prove it,\n",
            "Distance: 46.348480224609375\n",
            "\n",
            "Result: his question, and shrugged. I dont know, sir. I see. Mr. Brunner looked disappointed. Well, half credit, Mr. Jackson. Zeus did indeed feed Kronos a mixture of mustard and wine, which made him disgorge his other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titans stomach. The gods defeated their father, sliced him to pieces with his own scythe, and scattered his remains in Tartarus, the darkest part of the Underworld. On that happy\n",
            "Distance: 48.22768783569336\n",
            "\n",
            "Result: but things really started going bad last May, when our sixthgrade class took a field trip to Manhattan twentyeight mentalcase kids and two teachers on a yellow school bus, heading to the Metropolitan Museum of Art to look at ancient Greek and Roman stuff. I knowit sounds like torture. Most Yancy field trips were. But Mr. Brunner, our Latin teacher, was leading this trip, so I had hopes. Mr. Brunner was this middleaged guy in a motorized wheelchair. He had thinning hair and a scruffy beard and a frayed\n",
            "Distance: 51.83222961425781\n",
            "\n",
            "Result: was the king god, and God? Mr. Brunner asked. Titan, I corrected myself. And ... he didnt trust his kids, who were the gods. So, um, Kronos ate them, right? But his wife hid baby Zeus, and gave Kronos a rock to eat instead. And later, when Zeus grew up, he tricked his dad, Kronos, into barfing up his brothers and sisters Eeew! said one of the girls behind me. and so there was this big fight between the gods and the Titans, I continued, and the gods won. Some snickers from the group. Behind me, Nancy\n",
            "Distance: 52.132896423339844\n",
            "\n",
            "Result: it to. The whole group laughed. Mr. Brunner stopped his story. Mr. Jackson, he said, did you have a comment? My face was totally red. I said, No, sir. Mr. Brunner pointed to one of the pictures on the stele. Perhaps youll tell us what this picture represents? I looked at the carving, and felt a flush of relief, because I actually recognized it. Thats Kronos eating his kids, right? Yes, Mr. Brunner said, obviously not satisfied. And he did this because . . . Well... I racked my brain to remember. Kronos\n",
            "Distance: 52.8665771484375\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning:\n",
        "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
        "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
        "You will be able to reuse this secret in all of your notebooks.\n",
        "Please note that authentication is recommended but still optional to access public models or datasets.\n",
        "  warnings.warn(\n",
        "Result: pagesif you feel something stirring insidestop reading immediately. You might be one of us. And once you know that, its only a mat ter of time before they sense it too, and theyll come for you. Dont say I didnt warn you. My name is Percy Jackson. Im twelve years old. Until a few months ago, I was a boarding student at Yancy Academy, a private school for troubled kids in upstate New York. Am I a troubled kid? Yeah. You could say that. I could start at any point in my short miserable life to prove it,\n",
        "Distance: 46.348480224609375\n",
        "\n",
        "Result: his question, and shrugged. I dont know, sir. I see. Mr. Brunner looked disappointed. Well, half credit, Mr. Jackson. Zeus did indeed feed Kronos a mixture of mustard and wine, which made him disgorge his other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titans stomach. The gods defeated their father, sliced him to pieces with his own scythe, and scattered his remains in Tartarus, the darkest part of the Underworld. On that happy\n",
        "Distance: 48.22768783569336\n",
        "\n",
        "Result: but things really started going bad last May, when our sixthgrade class took a field trip to Manhattan twentyeight mentalcase kids and two teachers on a yellow school bus, heading to the Metropolitan Museum of Art to look at ancient Greek and Roman stuff. I knowit sounds like torture. Most Yancy field trips were. But Mr. Brunner, our Latin teacher, was leading this trip, so I had hopes. Mr. Brunner was this middleaged guy in a motorized wheelchair. He had thinning hair and a scruffy beard and a frayed\n",
        "Distance: 51.83222961425781\n",
        "\n",
        "Result: was the king god, and God? Mr. Brunner asked. Titan, I corrected myself. And ... he didnt trust his kids, who were the gods. So, um, Kronos ate them, right? But his wife hid baby Zeus, and gave Kronos a rock to eat instead. And later, when Zeus grew up, he tricked his dad, Kronos, into barfing up his brothers and sisters Eeew! said one of the girls behind me. and so there was this big fight between the gods and the Titans, I continued, and the gods won. Some snickers from the group. Behind me, Nancy\n",
        "Distance: 52.132896423339844\n",
        "\n",
        "Result: it to. The whole group laughed. Mr. Brunner stopped his story. Mr. Jackson, he said, did you have a comment? My face was totally red. I said, No, sir. Mr. Brunner pointed to one of the pictures on the stele. Perhaps youll tell us what this picture represents? I looked at the carving, and felt a flush of relief, because I actually recognized it. Thats Kronos eating his kids, right? Yes, Mr. Brunner said, obviously not satisfied. And he did this because . . . Well... I racked my brain to remember. Kronos\n",
        "Distance: 52.8665771484375\n"
      ],
      "metadata": {
        "id": "cdNpqW4A7ClR"
      },
      "id": "cdNpqW4A7ClR"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BENHsiBU7GuL"
      },
      "id": "BENHsiBU7GuL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$"
      ],
      "metadata": {
        "id": "ISJ1Sf7U6_nA"
      },
      "id": "ISJ1Sf7U6_nA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@"
      ],
      "metadata": {
        "id": "pBuz-W_a7L6p"
      },
      "id": "pBuz-W_a7L6p"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Ls5_--R7OM7"
      },
      "id": "8Ls5_--R7OM7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ST51Dz4V9h2V"
      },
      "id": "ST51Dz4V9h2V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kutfb8M9hzY"
      },
      "id": "6kutfb8M9hzY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "az6Wrtae9hvz"
      },
      "id": "az6Wrtae9hvz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Inventor"
      ],
      "metadata": {
        "id": "hBqeBUoH9htS"
      },
      "id": "hBqeBUoH9htS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات الضرورية\n",
        "#!pip install faiss-cpu pandas transformers\n",
        "\n",
        "# استخراج النصوص من ملف CSV باستخدام pandas\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_csv(file_path, Inventor):\n",
        "    \"\"\"\n",
        "    وظيفة لاستخراج النصوص من عمود معين في ملف CSV.\n",
        "    - file_path: مسار ملف CSV.\n",
        "    - text_column: اسم العمود الذي يحتوي على النصوص.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    if Inventor not in df.columns:\n",
        "        raise ValueError(f\"العمود '{Inventor}' غير موجود في ملف CSV.\")\n",
        "    return df[Inventor].dropna().tolist()  # استخراج النصوص وتجاهل القيم الفارغة\n",
        "\n",
        "# تنظيف النصوص\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    وظيفة لتنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # إزالة الحواشي\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)  # إزالة العلامات الخاصة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # إزالة الأسطر الفارغة\n",
        "    text = text.strip()  # إزالة المسافات الزائدة\n",
        "    return text\n",
        "\n",
        "# تحديد مسار ملف CSV واسم العمود\n",
        "csv_path = \"/content/inventors_and_inventions.csv\"  # ضع مسار ملف CSV هنا\n",
        "text_column = \"text\"  # اسم العمود الذي يحتوي على النصوص\n",
        "raw_texts = extract_text_from_csv(csv_path, text_column)\n",
        "\n",
        "# تنظيف النصوص المستخرجة\n",
        "cleaned_texts = [clean_text(text) for text in raw_texts]\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(texts, max_chunk_size=500):\n",
        "    chunks = []\n",
        "    for text in texts:\n",
        "        words = text.split()\n",
        "        chunk = []\n",
        "        for word in words:\n",
        "            chunk.append(word)\n",
        "            if len(\" \".join(chunk)) > max_chunk_size:\n",
        "                chunks.append(\" \".join(chunk))\n",
        "                chunk = []\n",
        "        if chunk:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(cleaned_texts)\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# إعداد الفهرس\n",
        "embedding_dim = 384  # حجم التضمين من النموذج\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 هو معيار المسافة\n",
        "\n",
        "# إضافة النصوص والتضمينات إلى الفهرس\n",
        "embeddings = []\n",
        "texts = []\n",
        "\n",
        "for chunk in text_chunks:\n",
        "    embedding = generate_embedding(chunk)\n",
        "    index.add(np.array([embedding], dtype=\"float32\"))\n",
        "    embeddings.append(embedding)\n",
        "    texts.append(chunk)\n",
        "\n",
        "# البحث في النصوص باستخدام Faiss\n",
        "def search_in_faiss(query, index, k=5):\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"What did Thomas Edison invent?\"\n",
        "results = search_in_faiss(query, index)\n",
        "\n",
        "# عرض النتائج\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "fBBRyx8H-Pcx",
        "outputId": "226f57b5-424d-4409-87bc-d59c5ccbd9dc"
      },
      "id": "fBBRyx8H-Pcx",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "العمود 'text' غير موجود في ملف CSV.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1cfba550c3c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/inventors_and_inventions.csv\"\u001b[0m  \u001b[0;31m# ضع مسار ملف CSV هنا\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtext_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text\"\u001b[0m  \u001b[0;31m# اسم العمود الذي يحتوي على النصوص\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mraw_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# تنظيف النصوص المستخرجة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-1cfba550c3c2>\u001b[0m in \u001b[0;36mextract_text_from_csv\u001b[0;34m(file_path, Inventor)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mInventor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"العمود '{Inventor}' غير موجود في ملف CSV.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInventor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# استخراج النصوص وتجاهل القيم الفارغة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: العمود 'text' غير موجود في ملف CSV."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات الضرورية\n",
        "#!pip install faiss-cpu pandas transformers\n",
        "\n",
        "# استخراج النصوص من ملف CSV باستخدام pandas\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_csv(file_path, text_column):\n",
        "    \"\"\"\n",
        "    وظيفة لاستخراج النصوص من عمود معين في ملف CSV.\n",
        "    - file_path: مسار ملف CSV.\n",
        "    - text_column: اسم العمود الذي يحتوي على النصوص.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"العمود '{text_column}' غير موجود في ملف CSV.\")\n",
        "    return df[text_column].dropna().tolist()  # استخراج النصوص وتجاهل القيم الفارغة\n",
        "\n",
        "# تنظيف النصوص\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    وظيفة لتنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # إزالة الحواشي\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)  # إزالة العلامات الخاصة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # إزالة الأسطر الفارغة\n",
        "    text = text.strip()  # إزالة المسافات الزائدة\n",
        "    return text\n",
        "\n",
        "# تحديد مسار ملف CSV واسم العمود\n",
        "csv_path = \"/content/inventors_and_inventions.csv\"  # ضع مسار ملف CSV هنا\n",
        "text_column = \"text\"  # اسم العمود الذي يحتوي على النصوص\n",
        "raw_texts = extract_text_from_csv(csv_path, text_column)\n",
        "\n",
        "# تنظيف النصوص المستخرجة\n",
        "cleaned_texts = [clean_text(text) for text in raw_texts]\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(texts, max_chunk_size=500):\n",
        "    chunks = []\n",
        "    for text in texts:\n",
        "        words = text.split()\n",
        "        chunk = []\n",
        "        for word in words:\n",
        "            chunk.append(word)\n",
        "            if len(\" \".join(chunk)) > max_chunk_size:\n",
        "                chunks.append(\" \".join(chunk))\n",
        "                chunk = []\n",
        "        if chunk:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(cleaned_texts)\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# إعداد الفهرس\n",
        "embedding_dim = 384  # حجم التضمين من النموذج\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 هو معيار المسافة\n",
        "\n",
        "# إضافة النصوص والتضمينات إلى الفهرس\n",
        "embeddings = []\n",
        "texts = []\n",
        "\n",
        "for chunk in text_chunks:\n",
        "    embedding = generate_embedding(chunk)\n",
        "    index.add(np.array([embedding], dtype=\"float32\"))\n",
        "    embeddings.append(embedding)\n",
        "    texts.append(chunk)\n",
        "\n",
        "# البحث في النصوص باستخدام Faiss\n",
        "def search_in_faiss(query, index, k=5):\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"What did Thomas Edison invent?\"\n",
        "results = search_in_faiss(query, index)\n",
        "\n",
        "# عرض النتائج\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "WPIaDxlk9hpp",
        "outputId": "e321a17d-5011-46ad-b5bd-d7cdd94a0db4"
      },
      "id": "WPIaDxlk9hpp",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "العمود 'text' غير موجود في ملف CSV.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a22d5bbaad55>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/inventors_and_inventions.csv\"\u001b[0m  \u001b[0;31m# ضع مسار ملف CSV هنا\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtext_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text\"\u001b[0m  \u001b[0;31m# اسم العمود الذي يحتوي على النصوص\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mraw_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# تنظيف النصوص المستخرجة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a22d5bbaad55>\u001b[0m in \u001b[0;36mextract_text_from_csv\u001b[0;34m(file_path, text_column)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtext_column\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"العمود '{text_column}' غير موجود في ملف CSV.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# استخراج النصوص وتجاهل القيم الفارغة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: العمود 'text' غير موجود في ملف CSV."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udF881cl92cv"
      },
      "id": "udF881cl92cv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/dataset.csv\"  # ضع مسار ملف CSV هنا\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# عرض أسماء الأعمدة\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "NpVr7dAo-xiA"
      },
      "id": "NpVr7dAo-xiA"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9oIzVM5E-xdq"
      },
      "id": "9oIzVM5E-xdq"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7XRqQzb7-xaJ"
      },
      "id": "7XRqQzb7-xaJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ماذا تفعل إذا كنت غير متأكد من اسم العمود؟\n",
        "يمكنك عرض أسماء الأعمدة في ملف CSV باستخدام الكود التالي:"
      ],
      "metadata": {
        "id": "SpGlwZK2-1ua"
      },
      "id": "SpGlwZK2-1ua"
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "Jn8R4xoD_eNw"
      },
      "id": "Jn8R4xoD_eNw"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/inventors_and_inventions.csv\"  # ضع مسار ملف CSV هنا\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# عرض أسماء الأعمدة\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cy55KSf-zY5",
        "outputId": "308fa29f-d7d0-4bf2-b33b-185083424b16"
      },
      "id": "1Cy55KSf-zY5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Inventor', 'Invention'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحديد مسار ملف CSV واسم العمود\n",
        "csv_path = \"/content/dataset.csv\"  # ضع مسار ملف CSV هنا\n",
        "text_column = \"Inventor\"  # اسم العمود الذي يحتوي على النصوص\n",
        "raw_texts = extract_text_from_csv(csv_path, text_column)\n",
        "\n",
        "# تنظيف النصوص المستخرجة\n",
        "cleaned_texts = [clean_text(text) for text in raw_texts]\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "text_chunks = split_text_into_chunks(cleaned_texts)\n",
        "\n",
        "# باقي الكود كما هو# تثبيت المكتبات الضرورية\n",
        "#!pip install faiss-cpu pandas transformers\n",
        "\n",
        "# استخراج النصوص من ملف CSV باستخدام pandas\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_csv(file_path, Inventor):\n",
        "    \"\"\"\n",
        "    وظيفة لاستخراج النصوص من عمود معين في ملف CSV.\n",
        "    - file_path: مسار ملف CSV.\n",
        "    - text_column: اسم العمود الذي يحتوي على النصوص.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    if Inventor not in df.columns:\n",
        "        raise ValueError(f\"العمود '{Inventor}' غير موجود في ملف CSV.\")\n",
        "    return df[Inventor].dropna().tolist()  # استخراج النصوص وتجاهل القيم الفارغة\n",
        "\n",
        "# تنظيف النصوص\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    وظيفة لتنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # إزالة الحواشي\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)  # إزالة العلامات الخاصة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # إزالة الأسطر الفارغة\n",
        "    text = text.strip()  # إزالة المسافات الزائدة\n",
        "    return text\n",
        "\n",
        "# تحديد مسار ملف CSV واسم العمود\n",
        "csv_path = \"/content/inventors_and_inventions.csv\"  # ضع مسار ملف CSV هنا\n",
        "text_column = \"text\"  # اسم العمود الذي يحتوي على النصوص\n",
        "raw_texts = extract_text_from_csv(csv_path, text_column)\n",
        "\n",
        "# تنظيف النصوص المستخرجة\n",
        "cleaned_texts = [clean_text(text) for text in raw_texts]\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(texts, max_chunk_size=500):\n",
        "    chunks = []\n",
        "    for text in texts:\n",
        "        words = text.split()\n",
        "        chunk = []\n",
        "        for word in words:\n",
        "            chunk.append(word)\n",
        "            if len(\" \".join(chunk)) > max_chunk_size:\n",
        "                chunks.append(\" \".join(chunk))\n",
        "                chunk = []\n",
        "        if chunk:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(cleaned_texts)\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# إعداد الفهرس\n",
        "embedding_dim = 384  # حجم التضمين من النموذج\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 هو معيار المسافة\n",
        "\n",
        "# إضافة النصوص والتضمينات إلى الفهرس\n",
        "embeddings = []\n",
        "texts = []\n",
        "\n",
        "for chunk in text_chunks:\n",
        "    embedding = generate_embedding(chunk)\n",
        "    index.add(np.array([embedding], dtype=\"float32\"))\n",
        "    embeddings.append(embedding)\n",
        "    texts.append(chunk)\n",
        "\n",
        "# البحث في النصوص باستخدام Faiss\n",
        "def search_in_faiss(query, index, k=5):\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"What did Thomas Edison invent?\"\n",
        "results = search_in_faiss(query, index)\n",
        "\n",
        "# عرض النتائج\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "id": "hpR4YR0B--OJ"
      },
      "id": "hpR4YR0B--OJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال مع داتا csvيخرج النص المشابه للسؤال"
      ],
      "metadata": {
        "id": "Iuz28Out_5xJ"
      },
      "id": "Iuz28Out_5xJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات الضرورية\n",
        "# !pip install faiss-cpu transformers pandas\n",
        "\n",
        "# استخراج النصوص من ملف CSV\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_csv(file_path, column_name):\n",
        "    \"\"\"\n",
        "    استخراج النصوص من عمود محدد في ملف CSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if column_name not in df.columns:\n",
        "            raise ValueError(f\"العمود '{column_name}' غير موجود في ملف CSV.\")\n",
        "        return df[column_name].dropna().tolist()\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"حدث خطأ أثناء قراءة ملف CSV: {e}\")\n",
        "\n",
        "# تنظيف النصوص\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    تنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # إزالة الحواشي\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)  # إزالة العلامات الخاصة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # إزالة الأسطر الفارغة\n",
        "    text = text.strip()  # إزالة المسافات الزائدة\n",
        "    return text\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(text_list, max_chunk_size=500):\n",
        "    chunks = []\n",
        "    for text in text_list:\n",
        "        words = text.split()\n",
        "        chunk = []\n",
        "        for word in words:\n",
        "            chunk.append(word)\n",
        "            if len(\" \".join(chunk)) > max_chunk_size:\n",
        "                chunks.append(\" \".join(chunk))\n",
        "                chunk = []\n",
        "        if chunk:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    \"\"\"\n",
        "    إنشاء تضمين للنص باستخدام نموذج Transformers.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def build_faiss_index(embeddings, dimension=384):\n",
        "    \"\"\"\n",
        "    إعداد فهرس Faiss وإضافة التضمينات.\n",
        "    \"\"\"\n",
        "    index = faiss.IndexFlatL2(dimension)  # L2 هو معيار المسافة\n",
        "    index.add(np.array(embeddings, dtype=\"float32\"))\n",
        "    return index\n",
        "\n",
        "# البحث في النصوص باستخدام Faiss\n",
        "def search_in_faiss(query, index, texts, k=5):\n",
        "    \"\"\"\n",
        "    البحث في النصوص باستخدام Faiss.\n",
        "    \"\"\"\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# مسار ملف CSV واسم العمود\n",
        "csv_path = \"/content/inventors_and_inventions.csv\"  # ضع مسار ملف CSV هنا\n",
        "text_column = \"Inventor\"  # اسم العمود الذي يحتوي على النصوص\n",
        "\n",
        "# استخراج النصوص وتنظيفها\n",
        "raw_texts = extract_text_from_csv(csv_path, text_column)\n",
        "cleaned_texts = [clean_text(text) for text in raw_texts]\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة\n",
        "text_chunks = split_text_into_chunks(cleaned_texts)\n",
        "\n",
        "# إنشاء التضمينات وبناء الفهرس\n",
        "embeddings = [generate_embedding(chunk) for chunk in text_chunks]\n",
        "index = build_faiss_index(embeddings)\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"Innovations in technology\"  # استعلام البحث\n",
        "results = search_in_faiss(query, index, text_chunks)\n",
        "\n",
        "# عرض النتائج\n",
        "print(\"نتائج البحث:\")\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSGFG9er_OvQ",
        "outputId": "377cbcfd-77ce-4320-b79f-e8daf6a83b4c"
      },
      "id": "YSGFG9er_OvQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "نتائج البحث:\n",
            "Result: Galileo Galilei\n",
            "Distance: 66.47154998779297\n",
            "\n",
            "Result: Steve Jobs\n",
            "Distance: 72.65122985839844\n",
            "\n",
            "Result: Guglielmo Marconi\n",
            "Distance: 72.67211151123047\n",
            "\n",
            "Result: Bill Gates\n",
            "Distance: 75.57966613769531\n",
            "\n",
            "Result: Thomas Edison\n",
            "Distance: 78.95977020263672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "على سبيل المثال:\n",
        "\n",
        "إذا أردت إرجاع 10 نتائج بدلاً من 5، يمكنك تعديل الكود كالتالي:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "results = search_in_faiss(query, index, text_chunks, k=10)\n",
        "بذلك ستتمكن من الحصول على عدد أكبر من النتائج."
      ],
      "metadata": {
        "id": "GpoOM8NPAPtz"
      },
      "id": "GpoOM8NPAPtz"
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات الضرورية\n",
        "# !pip install faiss-cpu transformers pandas\n",
        "\n",
        "# استخراج النصوص من ملف CSV\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_csv(file_path, column_name):\n",
        "    \"\"\"\n",
        "    استخراج النصوص من عمود محدد في ملف CSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if column_name not in df.columns:\n",
        "            raise ValueError(f\"العمود '{column_name}' غير موجود في ملف CSV.\")\n",
        "        return df[column_name].dropna().tolist()\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"حدث خطأ أثناء قراءة ملف CSV: {e}\")\n",
        "\n",
        "# تنظيف النصوص\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    تنظيف النصوص:\n",
        "    1. إزالة الحواشي (مثل [1] أو [5]).\n",
        "    2. إزالة الأسطر الفارغة أو المسافات الزائدة.\n",
        "    3. إزالة العلامات غير المرغوب فيها (مثل !، #، \"، إلخ).\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # إزالة الحواشي\n",
        "    text = re.sub(r'[^\\w\\s.,?!:؛،]', '', text)  # إزالة العلامات الخاصة\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # إزالة الأسطر الفارغة\n",
        "    text = text.strip()  # إزالة المسافات الزائدة\n",
        "    return text\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة لتسهيل التضمين\n",
        "def split_text_into_chunks(text_list, max_chunk_size=500):\n",
        "    chunks = []\n",
        "    for text in text_list:\n",
        "        words = text.split()\n",
        "        chunk = []\n",
        "        for word in words:\n",
        "            chunk.append(word)\n",
        "            if len(\" \".join(chunk)) > max_chunk_size:\n",
        "                chunks.append(\" \".join(chunk))\n",
        "                chunk = []\n",
        "        if chunk:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "# إنشاء التضمينات باستخدام Transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# تحميل النموذج\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "    \"\"\"\n",
        "    إنشاء تضمين للنص باستخدام نموذج Transformers.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # استخدام متوسط التضمينات\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# إعداد Faiss وإضافة التضمينات\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def build_faiss_index(embeddings, dimension=384):\n",
        "    \"\"\"\n",
        "    إعداد فهرس Faiss وإضافة التضمينات.\n",
        "    \"\"\"\n",
        "    index = faiss.IndexFlatL2(dimension)  # L2 هو معيار المسافة\n",
        "    index.add(np.array(embeddings, dtype=\"float32\"))\n",
        "    return index\n",
        "\n",
        "# البحث في النصوص باستخدام Faiss\n",
        "def search_in_faiss(query, index, texts, k=1):\n",
        "    \"\"\"\n",
        "    البحث في النصوص باستخدام Faiss.\n",
        "    \"\"\"\n",
        "    query_embedding = generate_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=\"float32\"), k)\n",
        "    results = [(texts[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# مسار ملف CSV واسم العمود\n",
        "csv_path = \"/content/inventors_and_inventions.csv\"  # ضع مسار ملف CSV هنا\n",
        "text_column = \"Inventor\"  # اسم العمود الذي يحتوي على النصوص\n",
        "\n",
        "# استخراج النصوص وتنظيفها\n",
        "raw_texts = extract_text_from_csv(csv_path, text_column)\n",
        "cleaned_texts = [clean_text(text) for text in raw_texts]\n",
        "\n",
        "# تقسيم النصوص إلى فقرات قصيرة\n",
        "text_chunks = split_text_into_chunks(cleaned_texts)\n",
        "\n",
        "# إنشاء التضمينات وبناء الفهرس\n",
        "embeddings = [generate_embedding(chunk) for chunk in text_chunks]\n",
        "index = build_faiss_index(embeddings)\n",
        "\n",
        "# اختبار البحث\n",
        "query = \"Thomas Edison\"  # استعلام البحث\n",
        "results = search_in_faiss(query, index, text_chunks)\n",
        "\n",
        "# عرض النتائج\n",
        "print(\"نتائج البحث:\")\n",
        "for result, distance in results:\n",
        "    print(f\"Result: {result}\\nDistance: {distance}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trj5Ek_G_ucR",
        "outputId": "21e47b43-88aa-4ed2-9c91-0eff78fb42a6"
      },
      "id": "Trj5Ek_G_ucR",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "نتائج البحث:\n",
            "Result: Thomas Edison\n",
            "Distance: 0.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6dbG72SKAlOW"
      },
      "id": "6dbG72SKAlOW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2669a7f4fd0459aaa0947a95b62c8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_393a43337cd84940baa6fae2a6c2fb06",
              "IPY_MODEL_b75f6717216d4fb3acf78da8dae2e31e",
              "IPY_MODEL_d100ef7008ff476c8d19e4fa526408c3"
            ],
            "layout": "IPY_MODEL_5e2228bcf86d422487ba866e6f26918e"
          }
        },
        "393a43337cd84940baa6fae2a6c2fb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac444d6a5094859a0d9ca64794cf167",
            "placeholder": "​",
            "style": "IPY_MODEL_70df2429efeb4969866f2b5e5ef6bf3b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b75f6717216d4fb3acf78da8dae2e31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a108055b866849fb834c4a15c13bb980",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a083248243d446e835c9317f1ffb55d",
            "value": 350
          }
        },
        "d100ef7008ff476c8d19e4fa526408c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9edc2c0b16245e1af696f5ea79cbc1f",
            "placeholder": "​",
            "style": "IPY_MODEL_bd55711ddfdb413d90c5521a49df0d76",
            "value": " 350/350 [00:00&lt;00:00, 6.15kB/s]"
          }
        },
        "5e2228bcf86d422487ba866e6f26918e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac444d6a5094859a0d9ca64794cf167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70df2429efeb4969866f2b5e5ef6bf3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a108055b866849fb834c4a15c13bb980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a083248243d446e835c9317f1ffb55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9edc2c0b16245e1af696f5ea79cbc1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd55711ddfdb413d90c5521a49df0d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f10ff21631456a9fa15eada44e6b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8001e002442d4d3191ca0faff38bb909",
              "IPY_MODEL_9cf6d221d6d2407097f06c19db8e5dcf",
              "IPY_MODEL_e0e9615d16c5468bbce612fc726e46b1"
            ],
            "layout": "IPY_MODEL_df91e21893b949afa41f56e3e9b4e4bb"
          }
        },
        "8001e002442d4d3191ca0faff38bb909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2f3729c48f4d7abc4fe62a2272955b",
            "placeholder": "​",
            "style": "IPY_MODEL_926683b60a944330b16780430c2cfef6",
            "value": "vocab.txt: 100%"
          }
        },
        "9cf6d221d6d2407097f06c19db8e5dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f90dae032fc84ccaa0b9bd1d36b2b6be",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_205804a230f342c6b2bc9d60a572f16d",
            "value": 231508
          }
        },
        "e0e9615d16c5468bbce612fc726e46b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e2391a2155748bc8a892cffffb56741",
            "placeholder": "​",
            "style": "IPY_MODEL_a317c4152a0f4651a12ae53a1ad3c626",
            "value": " 232k/232k [00:00&lt;00:00, 2.12MB/s]"
          }
        },
        "df91e21893b949afa41f56e3e9b4e4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca2f3729c48f4d7abc4fe62a2272955b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926683b60a944330b16780430c2cfef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f90dae032fc84ccaa0b9bd1d36b2b6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205804a230f342c6b2bc9d60a572f16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e2391a2155748bc8a892cffffb56741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a317c4152a0f4651a12ae53a1ad3c626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2365be37ae5a41a7930435d91d2b9fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_234dad56005344d59289b124c75ac6ad",
              "IPY_MODEL_9333a214f49b43c6ba44e3974a98c902",
              "IPY_MODEL_c59386e789124f36b163be9fb9ec917f"
            ],
            "layout": "IPY_MODEL_9c01ba895e584555b43c9c64fa196f49"
          }
        },
        "234dad56005344d59289b124c75ac6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b996e5cdce4eac8ba69fa0f508416b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8bb9d0e981443e884a6782ea725f95",
            "value": "tokenizer.json: 100%"
          }
        },
        "9333a214f49b43c6ba44e3974a98c902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8eef7df5ae4988bfe2c6f5330c8007",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_764f2b60e79f414ca8dee60142dc259c",
            "value": 466247
          }
        },
        "c59386e789124f36b163be9fb9ec917f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac043e7fc9b446fb6ec0fe91ba013d5",
            "placeholder": "​",
            "style": "IPY_MODEL_9fc57f979b5843938484f2dbe7297f40",
            "value": " 466k/466k [00:00&lt;00:00, 8.21MB/s]"
          }
        },
        "9c01ba895e584555b43c9c64fa196f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b996e5cdce4eac8ba69fa0f508416b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8bb9d0e981443e884a6782ea725f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd8eef7df5ae4988bfe2c6f5330c8007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764f2b60e79f414ca8dee60142dc259c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fac043e7fc9b446fb6ec0fe91ba013d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc57f979b5843938484f2dbe7297f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d102272ccec64321ab3ff2ed7fdae24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd257bad79af428d9da667d90d2592b7",
              "IPY_MODEL_1b20fa604fbd4e04b272e8d2ce20bc10",
              "IPY_MODEL_abb9250e525f40e7bd09e933934fddde"
            ],
            "layout": "IPY_MODEL_02f22386eb2e414bb94294391cd5ce2b"
          }
        },
        "cd257bad79af428d9da667d90d2592b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4923934eae9d45a5942742afb99ad431",
            "placeholder": "​",
            "style": "IPY_MODEL_0ff07ea06d094807add3ea669500c659",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1b20fa604fbd4e04b272e8d2ce20bc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9efe56965a5e4ed4a5c84e705144aab6",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb083cf52fcd4c7ba8f4e5c8705f3f87",
            "value": 112
          }
        },
        "abb9250e525f40e7bd09e933934fddde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce4d9065da24331bb5631d2aa3a02c1",
            "placeholder": "​",
            "style": "IPY_MODEL_ab98421aacc4463f97472b3a0b5a6f47",
            "value": " 112/112 [00:00&lt;00:00, 1.57kB/s]"
          }
        },
        "02f22386eb2e414bb94294391cd5ce2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4923934eae9d45a5942742afb99ad431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ff07ea06d094807add3ea669500c659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9efe56965a5e4ed4a5c84e705144aab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb083cf52fcd4c7ba8f4e5c8705f3f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dce4d9065da24331bb5631d2aa3a02c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab98421aacc4463f97472b3a0b5a6f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ff1b0c856747eeab9d9d93992a290d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14483e0574df4e67aa7cab42f16feb06",
              "IPY_MODEL_9622ba4b868244a1819362da5be397ad",
              "IPY_MODEL_fb881a0f97454918b8b27641d74ae673"
            ],
            "layout": "IPY_MODEL_5179088bfc074c2682995eecee1d1707"
          }
        },
        "14483e0574df4e67aa7cab42f16feb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ac7467ca614960899ea1b9e57c02c2",
            "placeholder": "​",
            "style": "IPY_MODEL_4c3ae808e3f74cb39c381286e630dc40",
            "value": "config.json: 100%"
          }
        },
        "9622ba4b868244a1819362da5be397ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fafc2de24a9493fab4c6fdaf112aa9f",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29df1193fd4f486894852a599960c302",
            "value": 612
          }
        },
        "fb881a0f97454918b8b27641d74ae673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629915ec289146ecaef60e29b33933ad",
            "placeholder": "​",
            "style": "IPY_MODEL_c5259f02f4704c80a3027583a10d1be8",
            "value": " 612/612 [00:00&lt;00:00, 7.65kB/s]"
          }
        },
        "5179088bfc074c2682995eecee1d1707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ac7467ca614960899ea1b9e57c02c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3ae808e3f74cb39c381286e630dc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fafc2de24a9493fab4c6fdaf112aa9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29df1193fd4f486894852a599960c302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "629915ec289146ecaef60e29b33933ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5259f02f4704c80a3027583a10d1be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa6598ce2fef4cb2b1a5f464f5fd26cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdc5cf4b35ac493091d1f828eda6046f",
              "IPY_MODEL_f28a35dd8b1847d881c0d713f1625d0d",
              "IPY_MODEL_fec3786d9a344fab8c9ba9575ea15cec"
            ],
            "layout": "IPY_MODEL_1da56b3aa79e445d89280adb163a8bae"
          }
        },
        "fdc5cf4b35ac493091d1f828eda6046f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da0b60984d847b6933b96c5904ba5ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f6247dc919bd4a7a94be5952a296ec55",
            "value": "model.safetensors: 100%"
          }
        },
        "f28a35dd8b1847d881c0d713f1625d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e12a0ee173470f9c58e3bd14458699",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ec35ec9f0654f85b33c7a5eeff07637",
            "value": 90868376
          }
        },
        "fec3786d9a344fab8c9ba9575ea15cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0ea7d4ef7ec4f80addde8979317fcd3",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc844de153b4933be5eb1f122cecf4a",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 122MB/s]"
          }
        },
        "1da56b3aa79e445d89280adb163a8bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da0b60984d847b6933b96c5904ba5ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6247dc919bd4a7a94be5952a296ec55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84e12a0ee173470f9c58e3bd14458699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec35ec9f0654f85b33c7a5eeff07637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0ea7d4ef7ec4f80addde8979317fcd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc844de153b4933be5eb1f122cecf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}